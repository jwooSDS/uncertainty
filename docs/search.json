[{"path":"index.html","id":"preface","chapter":"Preface","heading":"Preface","text":"","code":""},{"path":"index.html","id":"who-is-this-book-for","chapter":"Preface","heading":"Who is this book for?","text":"many books linear models, various expectations different levels familiarity statistical, mathematical, coding concepts. books generally fall one two camps:Little familiarity statistical mathematical concepts, fairly familiar coding. books tend written programmers want get data science. books tend explain linear models trying avoid statistical mathematical concepts much possible. books tend present linear models recipe format giving readers directions build models.drawback books readers get much understanding underlying concepts linear models. impossible give directions covering every possible scenario real world real data messy. Practitioners data science often think outside box order make linear models work particular data, difficult without understanding mathematical framework linear models.Familiarity mathematical notation introductory statistical concepts statistical inference, little familiarity coding. books tend written mathematicians (anyone strong background mathematics) want get data science. books cover mathematical framework linear models thoroughly.drawback books readers must comfortable mathematical notation. limits audience books people fairly thorough training mathematics. People without training get lost trying read books, understand need know mathematical foundations use linear models data science.book meant readable groups readers. foundational mathematical knowledge presented, written readable anyone. book also explain knowledge mean context data science. Practical advice, based foundational mathematical knowledge, also given.book accompanies course STAT 6021: Linear Models Data Science, Masters Data Science (MSDS) program University Virginia School Data Science.introductory statistics introductory programming pre-requisites entering MSDS program, book assumes basic knowledge statistical inference coding. Review materials covering concepts provided separately enrolled students.","code":""},{"path":"index.html","id":"chapters","chapter":"Preface","heading":"Chapters","text":"chapters book follows:Chapters ?? ?? focus core R skills needed: data wrangling data visualization. R skills needed perform regression analysis.Chapters ?? ?? focus core R skills needed: data wrangling data visualization. R skills needed perform regression analysis.Chapters 1, 2, ?? cover simple linear regression (SLR). simplest scenario regression one predictor one response variable quantitative. using scenario able clearly explain concepts regression moving practical multiple linear regression (MLR), involves multiple predictors.Chapters 1, 2, ?? cover simple linear regression (SLR). simplest scenario regression one predictor one response variable quantitative. using scenario able clearly explain concepts regression moving practical multiple linear regression (MLR), involves multiple predictors.Chapters ?? ?? cover multiple linear regression: multiple predictors one response variable quantitative.Chapters ?? ?? cover multiple linear regression: multiple predictors one response variable quantitative.Chapters ?? ?? cover logistic regression: response variable binary.Chapters ?? ?? cover logistic regression: response variable binary.","code":""},{"path":"index.html","id":"how-to-use-this-book","chapter":"Preface","heading":"How to use this book","text":"using provided R code chapter, please remember clear R environment whenever move new chapter. can done typing rm(list = ls()).using provided R code chapter, please remember clear R environment whenever move new chapter. can done typing rm(list = ls()).Chapters 1 ??, R tutorial provided last section. also clear R environment running code tutorials.Chapters 1 ??, R tutorial provided last section. also clear R environment running code tutorials.additional resources provided students enrolled STAT 6021. include:\nLearning objectives.\nExplainer videos.\nPractice questions.\nAssignments.\nadditional resources provided students enrolled STAT 6021. include:Learning objectives.Explainer videos.Practice questions.Assignments.","code":""},{"path":"index.html","id":"data-sets-used","chapter":"Preface","heading":"Data sets used","text":"tried use many open source data sets much possible readers can work various examples provided . However, data sets may open source shared statistics data science educators years teaching class (variations ) since 2013. goal eventually use open source data sets.","code":""},{"path":"index.html","id":"reporting-issues-with-this-book","chapter":"Preface","heading":"Reporting issues with this book","text":"book mostly compilation course notes originally written separate chapters. effort made fix typos, issues may still exist. find issues (typos, formatting, etc), please report https://github.com/jwooSDS/linear_models/issues. Please specific can, including providing specific section paragraph issue found.","code":""},{"path":"index.html","id":"other-resources","chapter":"Preface","heading":"Other resources","text":"resources readers may want check :OpenIntro Statistics, 4th ed. Diez, Cetinkaya-Rundel, Barr, OpenIntro. Get free PDF version https://leanpub.com/os, just set price want pay $0. good book introductory statistics.OpenIntro Statistics, 4th ed. Diez, Cetinkaya-Rundel, Barr, OpenIntro. Get free PDF version https://leanpub.com/os, just set price want pay $0. good book introductory statistics.Introduction Probability Data Science, Chan. https://probability4datascience.com/index.html. book covers fundamentals probability mathematics needed data science. good job explaining seemingly abstract mathematical concepts needed applied data science.Introduction Probability Data Science, Chan. https://probability4datascience.com/index.html. book covers fundamentals probability mathematics needed data science. good job explaining seemingly abstract mathematical concepts needed applied data science.Linear Models R, 2nd ed. Faraway. probably one books balances two camps wrote earlier. require familiarity matrices linear algebra though.Linear Models R, 2nd ed. Faraway. probably one books balances two camps wrote earlier. require familiarity matrices linear algebra though.Introduction Linear Regression Analysis, 5th 6th ed. Montgomery, Peck, Vining. may able access e-version book university library affiliated university. book mathematically rigorous useful interested mathematical proofs covered.Introduction Linear Regression Analysis, 5th 6th ed. Montgomery, Peck, Vining. may able access e-version book university library affiliated university. book mathematically rigorous useful interested mathematical proofs covered.Applied Linear Statistical Models (ALSM), Kutner, Nachtsheim, Neter, Li, 5th ed. book covers wide range topics linear models also mathematically rigorous.Applied Linear Statistical Models (ALSM), Kutner, Nachtsheim, Neter, Li, 5th ed. book covers wide range topics linear models also mathematically rigorous.Applied Linear Regression Models (ALRM), Kutner, Nachtsheim, Neter, 4th ed. ALRM first 14 chapters ALSM. second part ALSM covers topics Design Experiments, highly recommend interested topics.Applied Linear Regression Models (ALRM), Kutner, Nachtsheim, Neter, 4th ed. ALRM first 14 chapters ALSM. second part ALSM covers topics Design Experiments, highly recommend interested topics.","code":""},{"path":"slr.html","id":"slr","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"1 Basics with Simple Linear Regression (SLR)","text":"","code":""},{"path":"slr.html","id":"introduction-hi-again","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"1.1 Introduction HI AGAIN!!!!","text":"start module introducing simple linear regression model. Simple linear regression uses term “simple,” concerns study one predictor variable one quantitative response variable. contrast, multiple linear regression, study future modules, uses term “multiple,” concerns study two predictor variables one quantitative response variable. start simple linear regression much easier visualize concepts regression models one predictor variable.time , consider predictor variables quantitative. consider predictor variables categorical future modules.common way visualizing relationship one quantitative predictor variable one quantitative response variable scatter plot. simulated example , data 6000 UVa undergraduate students amount time spend studying week (minutes), many courses taking semester (3 4 credit courses).\nFigure 1.1: Scatterplot Study Time Number Courses Taken\nQuestions may include:study time number courses taken related one another?strong relationship?use data make prediction study time student scatterplot?confident prediction?questions can answered using simple linear regression.Note learning models just one response variable. cover multivariate regression, used one response variable. may confusion “multiple” linear regression “multivariate” regression due closeness terminology.","code":"\n##create dataframe\ndf<-data.frame(study,courses)\n\n##fit regression\nresult<-lm(study~courses, data=df)\n##create scatterplot with regression line overlaid\nplot(df$courses, df$study, xlab=\"# of Courses\", ylab=\"Study Time (Mins)\")\nabline(result)"},{"path":"slr.html","id":"basic-ideas-with-statistics","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"1.1.1 Basic Ideas with Statistics","text":"","code":""},{"path":"slr.html","id":"population-vs-sample","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"1.1.1.1 Population vs Sample","text":"Statistical methods usually used make inferences population based information sample.sample collection units actually measured surveyed study.population includes units interest.study time example , population UVa undergraduate students, sample 6000 students data displayed scatterplot.","code":""},{"path":"slr.html","id":"parameters-vs-statistics","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"1.1.1.2 Parameters vs Statistics","text":"Parameters numerical quantities describe population.Statistics numerical quantities describe sample.study time example, example parameter average study time among UVa undergraduate students (called population mean), example statistic average study time among 6000 UVa students data (called sample mean).Notice real life, rarely know actual numerical value parameter. use numerical value statistic estimate unknown numerical value corresponding parameter.also different notation parameters statistics. example,population mean denoted \\(\\mu\\).sample mean denoted \\(\\bar{x}\\).say \\(\\bar{x}\\) estimator \\(\\mu\\).important pay attention whether describing statistic (known value can calculated) parameter (unknown value).","code":""},{"path":"slr.html","id":"motivation","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"1.1.2 Motivation","text":"Linear regression models generally two primary uses:Prediction: Predict future value response variable, using information predictor variables.Association: Quantify relationship variables. change predictor variable change value response variable?always distinguish response variable, denoted \\(y\\), predictor variable, denoted \\(x\\). statistical models, say response variable can approximated mathematical function, denoted \\(f\\), predictor variable, .e.\\[\ny \\approx f(x).\n\\]\nOftentimes, write relationship \\[\ny = f(x) + \\epsilon,\n\\]\\(\\epsilon\\) denotes random error term, mean 0. error term predicted based data .various statistical methods estimate \\(f\\). estimate \\(f\\), can use method prediction / association.Using study time example :prediction example: student intends take 4 courses semester. student’s predicted study time, average?association example: want see taking courses increases study time.","code":""},{"path":"slr.html","id":"practice-questions","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"1.1.2.1 Practice questions","text":"examples , using regression model prediction association?early morning heading rest day. want know weather forecast rest day know wear.early morning heading rest day. want know weather forecast rest day know wear.executive sports league wants assess increasing length commercial breaks may impact enjoyment sports fans watch games TV.executive sports league wants assess increasing length commercial breaks may impact enjoyment sports fans watch games TV.Education Secretary like evaluate certain factors use technology classrooms investment teacher training teacher pay associated reading skills students.Education Secretary like evaluate certain factors use technology classrooms investment teacher training teacher pay associated reading skills students.buying home, prospective buyer like know home - - priced, given characteristics.buying home, prospective buyer like know home - - priced, given characteristics.","code":""},{"path":"slr.html","id":"simple-linear-regression-slr","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"1.2 Simple Linear Regression (SLR)","text":"simple linear regression (SLR), function \\(f\\) relates predictor variable response variable typically \\(\\beta_0 + \\beta_1 x\\). Mathematically, express \\[\ny \\approx \\beta_0 + \\beta_1 x,\n\\]words, response variable approximately linear relationship predictor variable.SLR, relationship explicitly formulated simple linear regression equation:\\[\\begin{equation}\nE(y|x)=\\beta_0+\\beta_{1}x.\n\\tag{1.1}\n\\end{equation}\\]\\(\\beta_0\\) \\(\\beta_1\\) parameters SLR equation, want estimate .\\(\\beta_0\\) \\(\\beta_1\\) parameters SLR equation, want estimate .parameters sometimes called regression coefficients.parameters sometimes called regression coefficients.\\(\\beta_1\\) also called slope. denotes change \\(y\\), average, \\(x\\) increases one unit.\\(\\beta_1\\) also called slope. denotes change \\(y\\), average, \\(x\\) increases one unit.\\(\\beta_0\\) also called intercept. denotes average \\(y\\) \\(x=0\\).\\(\\beta_0\\) also called intercept. denotes average \\(y\\) \\(x=0\\).notation left hand side (1.1) denotes expected value response variable, fixed value predictor variable. (1.1) implies , value predictor variable \\(x\\), expected value response variable \\(y\\) \\(\\beta_0+\\beta_{1}x\\). expected value also population mean. Applying (1.1) study time example, implies :\nstudents take 3 courses, expected study time equal \\(\\beta_0 + 3\\beta_1\\),\nstudents take 4 courses, expected study time equal \\(\\beta_0 + 4\\beta_1\\),\nstudents take 5 courses, expected study time equal \\(\\beta_0 + 5\\beta_1\\).\nnotation left hand side (1.1) denotes expected value response variable, fixed value predictor variable. (1.1) implies , value predictor variable \\(x\\), expected value response variable \\(y\\) \\(\\beta_0+\\beta_{1}x\\). expected value also population mean. Applying (1.1) study time example, implies :students take 3 courses, expected study time equal \\(\\beta_0 + 3\\beta_1\\),students take 4 courses, expected study time equal \\(\\beta_0 + 4\\beta_1\\),students take 5 courses, expected study time equal \\(\\beta_0 + 5\\beta_1\\).\\(f(x) = \\beta_0 + \\beta_1x\\) gives us value expected value response variable specific value predictor variable. , value predictor variable, value response variable constant. say value \\(x\\), response variable \\(y\\) variance. variance response variable value \\(x\\) variance error term, \\(\\epsilon\\). Thus simple linear regression model\\[\\begin{equation}\ny=\\beta_0+\\beta_{1} x + \\epsilon.\n\\tag{1.2}\n\\end{equation}\\]need make assumptions error term \\(\\epsilon\\). Generally, assumptions :errors mean 0.errors variance denoted \\(\\sigma^2\\). Notice variance constant.errors independent.errors normally distributed.(1.2), notice another parameter, \\(\\sigma^2\\).go detail assumptions mean, assess whether met, module ??.assumptions mean value predictor variable \\(x\\), response variable:follows normal distribution,mean equal \\(\\beta_0+\\beta_{1} x\\),variance equal \\(\\sigma^2\\).Using study time example, means :students take 3 courses, distribution study times \\(N(\\beta_0 + 3\\beta_1, \\sigma^2)\\).students take 4 courses, distribution study times \\(N(\\beta_0 + 4\\beta_1, \\sigma^2)\\).students take 5 courses, distribution study times \\(N(\\beta_0 + 5\\beta_1, \\sigma^2)\\).subset dataframe three subsets, one students take 3 courses, another subset students take 4 courses, another subset students take 5 courses, create density plot study times subset, density plot follow normal distribution, different means, spread.Let us take look density plots next.Notice plots normal, different means (centers), similar spreads.Please see associated video explanation distribution response variable, value predictor variable, SLR setting.","code":"\nlibrary(tidyverse)\n##subset dataframe\nx.3<-df[which(df$courses==3),]\n##density plot of study time for students taking 3 courses\nggplot(x.3,aes(x=study))+\n  geom_density()+\n  labs(x=\"Study Time (Mins)\", title=\"Dist of Study Times with 3 Courses\")\n##subset dataframe\nx.4<-df[which(df$courses==4),]\n##density plot of study time for students taking 4 courses\nggplot(x.4,aes(x=study))+\n  geom_density()+\n  labs(x=\"Study Time (Mins)\", title=\"Dist of Study Times with 4 Courses\")\n##subset dataframe\nx.5<-df[which(df$courses==5),]\n##density plot of study time for students taking 5 courses\nggplot(x.5,aes(x=study))+\n  geom_density()+\n  labs(x=\"Study Time (Mins)\", title=\"Dist of Study Times with 5 Courses\")"},{"path":"slr.html","id":"estimating-regression-coefficients-in-slr","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"1.3 Estimating Regression Coefficients in SLR","text":"(1.1) (1.2), noted estimate regression coefficients \\(\\beta_0, \\beta_1\\) well parameter \\(\\sigma^2\\) associated error term. mentioned earlier, unable obtain numerical values parameters data entire population. use data sample estimate parameters.estimate \\(\\beta_0,\\beta_1\\) using \\(\\hat{\\beta}_0,\\hat{\\beta}_1\\) based sample observations \\((x_i,y_i)\\) size \\(n\\).subscripts associated response predictor variables denote data point value belongs . Let us take look first rows data frame study time example:example, \\(x_1\\) denotes number courses taken student number 1 dataframe, 3. \\(y_4\\) denotes study time student number 4 dataframe, 378.0196456.Following (1.1) (1.2), sample versions \\[\\begin{equation}\n\\hat{y}=\\hat{\\beta}_0+\\hat{\\beta}_1 x\n\\tag{1.3}\n\\end{equation}\\]\\[\\begin{equation}\ny=\\hat{\\beta}_0+\\hat{\\beta}_1 x + e\n\\tag{1.4}\n\\end{equation}\\]respectively. (1.3) called estimated SLR equation, fitted SLR equation. (1.4) called estimated SLR model.\\(\\hat{\\beta}_1,\\hat{\\beta}_0\\) estimators \\(\\beta_1,\\beta_0\\) respectively. estimators can interpreted following manner:\\(\\hat{\\beta}_1\\) denotes change predicted \\(y\\) \\(x\\) increases 1 unit. Alternatively, denotes change \\(y\\), average, \\(x\\) increases 1 unit.\\(\\hat{\\beta}_0\\) denotes predicted \\(y\\) \\(x=0\\). Alternatively, denotes average \\(y\\) \\(x=0\\).(1.4), notice use \\(e\\) denote residual, words, “error” sample.(1.3) (1.4), following quantities can compute:\\[\\begin{equation}\n\\text{Predicted/Fitted values: } \\hat{y}_i = \\hat{\\beta}_0+\\hat{\\beta}_1 x_i.\n\\tag{1.5}\n\\end{equation}\\]\\[\\begin{equation}\n\\text{Residuals: } e_i = y_i-\\hat{y}_i.\n\\tag{1.6}\n\\end{equation}\\]\\[\\begin{equation}\n\\text{Sum Squared Residuals: } SS_{res} =  \\sum\\limits_{=1}^n(y_i-\\hat{y}_i)^2.\n\\tag{1.7}\n\\end{equation}\\]compute estimated coefficients \\(\\hat{\\beta}_1,\\hat{\\beta}_0\\) using method least squares, .e. choose numerical values \\(\\hat{\\beta}_1,\\hat{\\beta}_0\\) minimize \\(SS_{res}\\) given (1.7).minimizing \\(SS_{res}\\) respect \\(\\hat{\\beta}_0\\) \\(\\hat{\\beta}_1\\), estimated coefficients simple linear regression equation \\[\\begin{equation}\n\\hat{\\beta}_1 = \\frac{\\sum\\limits_{=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum\\limits_{=1}^n(x_i-\\bar{x})^2}\n\\tag{1.8}\n\\end{equation}\\]\\[\\begin{equation}\n\\hat{\\beta}_0 = \\bar{y}- \\hat{\\beta}_1 \\bar{x}\n\\tag{1.9}\n\\end{equation}\\]\\(\\hat{\\beta}_1, \\hat{\\beta}_0\\) called least squares estimators.minimization \\(SS_{res}\\) respect \\(\\hat{\\beta}_0\\) \\(\\hat{\\beta}_1\\) done taking partial derivatives (1.7) respect \\(\\hat{\\beta}_1\\) \\(\\hat{\\beta}_0\\), setting two partial derivatives equal 0, solving two equations \\(\\hat{\\beta}_1\\) \\(\\hat{\\beta}_0\\).Let’s take look estimated coefficients study time example:sample 6000 students, \\(\\hat{\\beta}_1\\) = 120.3930985. predicted study time increases 120.3930985 minutes additional course taken.\\(\\hat{\\beta}_0\\) = 58.4482853. predicted study time 58.4482853 courses taken. Notice value make sense, student taking 0 courses. look data, number courses taken 3, 4, 5. use regression \\(3 \\leq x \\leq 5\\). use values \\(x\\) outside range data. Making predictions response variable predictors outside range data called extrapolation done.","code":"\nhead(df)##      study courses\n## 1 429.8311       3\n## 2 458.4588       3\n## 3 391.9406       3\n## 4 378.0196       3\n## 5 397.9856       3\n## 6 405.7145       3\n##fit regression\nresult<-lm(study~courses, data=df)\n##print out the estimated coefficients\nresult## \n## Call:\n## lm(formula = study ~ courses, data = df)\n## \n## Coefficients:\n## (Intercept)      courses  \n##       58.45       120.39"},{"path":"slr.html","id":"estimating-variance-of-errors-in-slr","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"1.4 Estimating Variance of Errors in SLR","text":"estimator \\(\\sigma^2\\), variance error terms (also variance probability distribution \\(y\\) given \\(x\\)) \n\\[\\begin{equation}\ns^2 = MS_{res} = \\frac{SS_{res}}{n-2} = \\frac{\\sum\\limits_{=1}^n e_i^2}{n-2},\n\\tag{1.10}\n\\end{equation}\\]\\(MS_{res}\\) called mean squared residuals.\\(\\sigma^2\\), variance error terms, measures spread response variable, value \\(x\\). smaller , closer data points regression equation.","code":""},{"path":"slr.html","id":"practice-questions-1","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"1.4.1 Practice questions","text":"Take look scatterplot study time number courses taken, Figure 1.1. plot, label following:estimated SLR equationthe fitted value \\(x=3\\), \\(x=4\\), \\(x=5\\).residual data point plot choosing.Try first, view associated video see labeled plot correctly!","code":""},{"path":"slr.html","id":"assessing-linear-association","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"1.5 Assessing Linear Association","text":"noted earlier, variance error terms inform us close data points estimated SLR equation. smaller variance error terms, closer data points estimated SLR equation. turn implies linear relationship variables stronger.learn common measures used quantify strength linear relationship response predictor variables. , need define terms.","code":""},{"path":"slr.html","id":"sum-of-squares","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"1.5.1 Sum of squares","text":"\\[\\begin{equation}\n\\text{Total Sum Squares: } SS_T = \\sum\\limits_{=1}^{n} (y_i - \\bar{y})^{2}.\n\\tag{1.11}\n\\end{equation}\\]Total sum squares defined total variance response variable. larger value , larger spread response variable.\\[\\begin{equation}\n\\text{Regression sum squares: } SS_R = \\sum\\limits_{=1}^{n} (\\hat{y_i} - \\bar{y})^{2}.\n\\tag{1.12}\n\\end{equation}\\]Regression sum squares defined variance response variable can explained regression.also residual sum squares, \\(SS_{res}\\). mathematical formulation given (1.7). defined variance response variable explained regression.can shown \\[\\begin{equation}\nSS_T = SS_R + SS_{res}.\n\\tag{1.13}\n\\end{equation}\\]sums squares associated degrees freedom (df):df \\(SS_R\\): \\(df_R = 1\\)df \\(SS_{res}\\): \\(df_{res} = n-2\\)df \\(SS_T\\): \\(df_T = n-1\\)Please see associated video explanation concept behind degrees freedom.","code":""},{"path":"slr.html","id":"anova-table","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"1.5.2 ANOVA Table","text":"Information regarding sums squares usually presented form ANOVA (analysis variance) table:Note:Dividing sum square corresponding degrees freedom gives corresponding mean square.last column, report \\(F\\) statistic, equal \\(\\frac{MS_R}{MS_{res}}\\). \\(F\\) statistic associated ANOVA F test, look detail next subsection.obtain ANOVA table study time example:Notice R print information line regarding \\(SS_T\\).","code":"\nanova(result)## Analysis of Variance Table\n## \n## Response: study\n##             Df   Sum Sq  Mean Sq F value    Pr(>F)    \n## courses      1 57977993 57977993   65404 < 2.2e-16 ***\n## Residuals 5998  5317017      886                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"slr.html","id":"anova-f-test","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"1.5.3 ANOVA \\(F\\) Test","text":"SLR, ANOVA \\(F\\) statistic ANOVA table can used test slope SLR equation 0 . words, means whether linear association variables . slope 0, means changes value predictor variable change value response variable, average; hence variables linearly associated.null alternative hypotheses :\\[\nH_0: \\beta_1 = 0, H_a: \\beta_1 \\neq 0.\n\\]\ntest statistic \\[\\begin{equation}\nF = \\frac{MS_R}{MS_{res}}\n\\tag{1.14}\n\\end{equation}\\]compared \\(F_{1,n-2}\\) distribution. Note \\(F_{1,n-2}\\) read F distribution 1 \\(n-2\\) degrees freedom.Going back study time example, \\(F\\) statistic 6.5403586^{4}. critical value can found usingSince test statistic larger critical value, reject null hypothesis. data support claim slope different 0, words, linear association study time number courses taken.","code":"\nqf(1-0.05, 1, 6000-2)## [1] 3.84301"},{"path":"slr.html","id":"coefficient-of-determination","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"1.5.4 Coefficient of determination","text":"coefficient determination, \\(R^2\\), \\[\\begin{equation}\nR^{2} = \\frac{SS_R}{SS_T} = 1 - \\frac{SS_{res}}{SS_T}.\n\\tag{1.15}\n\\end{equation}\\]\\(R^{2}\\) indication well data fits model. context simple linear regression, denotes proportion variance response variable explained predictor.notes \\(R^2\\):\\(0 \\leq R^2 \\leq 1\\).Values closer 1 indicate better fit; values closer 0 indicate poorer fit.Sometimes reported percentage.obtain \\(R^2\\) study time example:implies proportion variance study time can explained number courses taken 0.9159963.","code":"\nanova.tab<-anova(result)\n##SST not provided, so we add up SSR and SSres\nSST<-sum(anova.tab$\"Sum Sq\")\n##R2\nanova.tab$\"Sum Sq\"[1]/SST## [1] 0.9159963"},{"path":"slr.html","id":"correlation","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"1.5.5 Correlation","text":"measure used quantify strength linear association two quantitative variables sample correlation. sample correlation, \\(\\mbox{Corr}(x,y)\\) \\(r\\), given \\[\\begin{equation}\nr = \\frac{\\sum\\limits_{=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum\\limits_{=1}^{n}(x_i - \\bar{x})^{2}(y_i - \\bar{y})^{2}}}.\n\\tag{1.16}\n\\end{equation}\\]notes \\(r\\):\\(-1 \\leq r \\leq 1\\).Sign correlation indicates direction association. positive value indicates positive linear association: predictor variable increases, response variable, average. negative value indicates negative linear association: predictor variable increases, response variable decreases, average.Values closer 1 -1 indicate stronger linear association; values closer 0 indicate weaker linear association.SLR, turns \\(r^2 = R^2\\).Using study time example, correlation study time number courses taken isThis value indicates strong positive linear association study time number courses taken (remember simulated data real).","code":"\ncor(df$study, df$courses)## [1] 0.9570769"},{"path":"slr.html","id":"how-strong-is-strong","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"1.5.5.1 How strong is strong?","text":"question often raised large magnitude sample correlation considered strong? answer : depends context. conducting experiment governed scientific laws (e.g experiment verifying Newton’s 2nd law \\(F = ma\\)), expect extremely high correlation. correlation 0.9 instance may considered weak. value correlation compared correlations similar studies domain determine strong .","code":""},{"path":"slr.html","id":"a-word-of-caution","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"1.6 A Word of Caution","text":"able use measures learned (correlation, \\(R^2\\)) interpret estimated regression coefficients, must verify via scatterplot association two variables approximately linear. see non linear pattern scatterplot, use interpret values. learn remedy situation see non linear pattern scatterplot module 5.Please see associated video demonstration looking scatterplot can lead misleading interpretations.","code":""},{"path":"slr.html","id":"r-tutorial","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"1.7 R Tutorial","text":"tutorial, work dataset elmhurst openintro package R.Type ?openintro::elmhurst read documentation datasets R. Always seek understand background data! key pieces information :random sample 50 students (freshman 2011 class Elmhurst College).Family income student (units missing).Gift aid, $1000s.want explore family income may related gift aid, simple linear regression framework.","code":"\nlibrary(tidyverse)\nlibrary(openintro)\nData<-openintro::elmhurst"},{"path":"slr.html","id":"visualization","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"Visualization","text":"always verify scatterplot relationship (approximately) linear proceeding correlation simple linear regression!note observations fairly evenly scattered sides regression line, linear association exists. see negative linear association. family income increases, gift aid, average, decreases.also see observation weird values may warrant investigation.","code":"\n##scatterplot of gift aid against family income\nggplot2::ggplot(Data, aes(x=family_income,y=gift_aid))+\n  geom_point()+\n  geom_smooth(method = \"lm\", se=FALSE)+\n  labs(x=\"Family Income\", y=\"Gift Aid\", title=\"Scatterplot of Gift Aid against Family\")"},{"path":"slr.html","id":"regression","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"Regression","text":"use lm() function fit regression model:Use summary() function display relevant information regression:see following values:\\(\\hat{\\beta}_1 =\\) -0.0430717. estimated slope informs us predicted gift aid decreases 0.0430717 thousands dollars ($43.07) per unit increase family income.\\(\\hat{\\beta}_0 =\\) 24.319329. students family income, predicted gift aid $24 319.33. Note: scatterplot, observation 0 family income. must careful extrapolating making predictions regression. make predictions family incomes minimum maximum values family incomes data.\\(s\\) = 4.7825989, estimate standard deviation error terms. reported residual standard error R. Squaring gives estimated variance.\\(F\\) = 15.8772043. value ANOVA \\(F\\) statistic. corresponding p-value reported. Since p-value small, reject null hypothesis. data support claim linear association gift aid family income.\\(R^2 =\\) 0.2485582. coefficient determination informs us 24.86% variation gift aid can explained family income.","code":"\n##regress gift aid against family income\nresult<-lm(gift_aid~family_income, data=Data)\n##look at information regarding regression\nsummary(result)## \n## Call:\n## lm(formula = gift_aid ~ family_income, data = Data)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -10.1128  -3.6234  -0.2161   3.1587  11.5707 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)   24.31933    1.29145  18.831  < 2e-16 ***\n## family_income -0.04307    0.01081  -3.985 0.000229 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 4.783 on 48 degrees of freedom\n## Multiple R-squared:  0.2486, Adjusted R-squared:  0.2329 \n## F-statistic: 15.88 on 1 and 48 DF,  p-value: 0.0002289"},{"path":"slr.html","id":"extract-values-from-r-objects","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"Extract values from R objects","text":"can actually extract values reported summary(result). see can extracted R object, use names() function:extract estimated coefficients:Notice information presented table. extract specific value, can specify row column indices:, extract values residual standard error, ANOVA F statistic, \\(R^2\\).","code":"\n##see what can be extracted from summary(result)\nnames(summary(result))##  [1] \"call\"          \"terms\"         \"residuals\"     \"coefficients\" \n##  [5] \"aliased\"       \"sigma\"         \"df\"            \"r.squared\"    \n##  [9] \"adj.r.squared\" \"fstatistic\"    \"cov.unscaled\"\n##extract coefficients\nsummary(result)$coefficients##                  Estimate Std. Error   t value     Pr(>|t|)\n## (Intercept)   24.31932901 1.29145027 18.831022 8.281020e-24\n## family_income -0.04307165 0.01080947 -3.984621 2.288734e-04\n##extract slope\nsummary(result)$coefficients[2,1]## [1] -0.04307165\n##extract intercept\nsummary(result)$coefficients[1,1]## [1] 24.31933"},{"path":"slr.html","id":"prediction","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"Prediction","text":"use regression models prediction. Suppose want predict gift aid student family income 50 thousand dollars (assuming unit thousands dollars). use predict() function:student’s predicted gift aid $22 165.75. Alternatively, calculated plugging \\(x=50\\) estimated SLR equation:","code":"\n##create data point for prediction\nnewdata<-data.frame(family_income=50)\n##predicted gift aid when x=50\npredict(result,newdata)##        1 \n## 22.16575\nsummary(result)$coefficients[1,1] + summary(result)$coefficients[2,1]*50## [1] 22.16575"},{"path":"slr.html","id":"anova-table-1","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"ANOVA table","text":"use anova() function display ANOVA tableThe report \\(F\\) statistic value reported earlier summary(result).first line output gives \\(SS_{R}\\), second line gives \\(SS_{res}\\). function doesn’t provide \\(SS_T\\), know \\(SS_T = SS_{R} + SS_{res}\\)., see can extracted anova.tab:\\(SS_T\\) can easily calculated:\\(R^2\\) reported 0.2485582. verify using ANOVA table:","code":"\nanova.tab<-anova(result)\nanova.tab## Analysis of Variance Table\n## \n## Response: gift_aid\n##               Df  Sum Sq Mean Sq F value    Pr(>F)    \n## family_income  1  363.16  363.16  15.877 0.0002289 ***\n## Residuals     48 1097.92   22.87                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nnames(anova.tab)## [1] \"Df\"      \"Sum Sq\"  \"Mean Sq\" \"F value\" \"Pr(>F)\"\nSST<-sum(anova.tab$\"Sum Sq\")\nSST## [1] 1461.079\nanova.tab$\"Sum Sq\"[1]/SST## [1] 0.2485582"},{"path":"slr.html","id":"correlation-1","chapter":"1 Basics with Simple Linear Regression (SLR)","heading":"Correlation","text":"use cor() function find correlation two quantitative variables:correlation -0.4985561. moderate, negative linear association family income gift aid.","code":"\n##correlation\ncor(Data$family_income,Data$gift_aid)## [1] -0.4985561"},{"path":"inf.html","id":"inf","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"2 Inference with Simple Linear Regression (SLR)","text":"","code":""},{"path":"inf.html","id":"introduction","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"2.1 Introduction","text":"Oftentimes, data collect come random sample representative population interest. common example election poll presidential election. Random sampling allows sample representative population. However, obtain another random sample, characteristics new sample unlikely exactly first sample. example, sample proportion vote certain party unlikely random samples. tells us even representative samples, sample proportions unlikely equal population proportion, sample proportions vary sample sample.Dr. W. Edwards Deming’s Red Bead experiment illustrates concept. video experiment can found .video, number red beads, represent bad products, varies time worker obtains random sample 50 beads. fact number red beads increases second sample indicate performed task worse, increase due random variation associated samples.Note: Deming’s Red Bead experiment developed illustrate concepts associated management. best known work developing Japanese economy World War II. able find many blogs/articles discussing experiment World Wide Web. Although many articles discuss experiment applies management, can used illustrate concepts variation.idea extends slope intercept regression line. estimated slope intercept vary sample sample unlikely equal population slope intercept. inferential statistics, use hypothesis tests confidence intervals aid us accounting random variation. module, learn account quantify random variation associated estimated regression model, interpret estimated regression model accounting random variation.","code":""},{"path":"inf.html","id":"review-from-previous-module","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"2.1.1 Review from previous module","text":"simple linear regression model written \\[\\begin{equation}\ny=\\beta_0+\\beta_{1} x + \\epsilon.\n\\tag{2.1}\n\\end{equation}\\]make assumptions error term \\(\\epsilon\\). :errors mean 0.errors variance denoted \\(\\sigma^2\\). Notice variance constant.errors independent.errors normally distributed.assumptions allow us derive distributional properties associated least squares estimators \\(\\hat{\\beta}_0, \\hat{\\beta}_1\\), enables us compute reliable confidence intervals perform hypothesis tests SLR reliably.\\(\\hat{\\beta}_1,\\hat{\\beta}_0\\) estimators \\(\\beta_1,\\beta_0\\) respectively. estimators can interpreted following manner:\\(\\hat{\\beta}_1\\) denotes change predicted \\(y\\) \\(x\\) increases 1 unit. Alternatively, denotes change \\(y\\), average, \\(x\\) increases 1 unit.\\(\\hat{\\beta}_0\\) denotes predicted \\(y\\) \\(x=0\\). Alternatively, denotes average \\(y\\) \\(x=0\\).values estimators vary sample sample?","code":""},{"path":"inf.html","id":"hypothesis-testing-in-slr","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"2.2 Hypothesis Testing in SLR","text":"","code":""},{"path":"inf.html","id":"distribution-of-least-squares-estimators","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"2.2.1 Distribution of least squares estimators","text":"Gauss Markov Theorem: assumptions regression model, least squares estimators \\(\\hat{\\beta}_1\\) \\(\\hat{\\beta}_0\\) unbiased minimum variance among unbiased linear estimators.Thus, least squares estimators following properties:\\(\\mbox{E}(\\hat{\\beta}_1) = \\beta_1\\), \\(\\mbox{E}(\\hat{\\beta}_0) = \\beta_0\\)Note: estimator unbiased expected value exactly equal parameter estimating.variance \\(\\hat{\\beta}_1\\) \\[\\begin{equation}\n\\mbox{Var}(\\hat{\\beta}_1) = \\frac{\\sigma^{2}}{\\sum{(x_{}-\\bar{x})^{2}}}\n\\tag{2.2}\n\\end{equation}\\]variance \\(\\hat{\\beta}_0\\) \\[\\begin{equation}\n\\mbox{Var}(\\hat{\\beta}_0) = \\sigma^2 \\left[\\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum (x_i -\\bar{x})^2}\\right]\n\\tag{2.3}\n\\end{equation}\\]\\(\\hat{\\beta}_1\\) \\(\\hat{\\beta}_0\\) follow normal distribution.Note (2.2) (2.3), use \\(s^2 = MS_{res}\\) estimate \\(\\sigma^2\\) since \\(\\sigma^2\\) unknown value.imply standardize \\(\\hat{\\beta}_1\\) \\(\\hat{\\beta}_0\\), standardized quantities follow \\(t_{n-2}\\) distribution, .e.\\[\\begin{equation}\n\\frac{\\hat{\\beta}_1 - \\beta_1}{se(\\hat{\\beta}_1)}\\sim t_{n-2}\n\\tag{2.4}\n\\end{equation}\\]\\[\\begin{equation}\n\\frac{\\hat{\\beta}_0 - \\beta_0}{se(\\hat{\\beta}_0)}\\sim t_{n-2},\n\\tag{2.5}\n\\end{equation}\\]\\[\\begin{equation}\nse(\\hat{\\beta}_1) = \\sqrt{\\frac{MS_{res}}{\\sum{(x_{}-\\bar{x})^{2}}}} = \\frac{s}{\\sqrt{\\sum{(x_{}-\\bar{x})^{2}}}}\n\\tag{2.6}\n\\end{equation}\\]\\[\\begin{equation}\nse(\\hat{\\beta}_0) = \\sqrt{MS_{res}\\left[\\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum (x_i -\\bar{x})^2}\\right]} = s \\sqrt{\\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum (x_i -\\bar{x})^2}}\n\\tag{2.7}\n\\end{equation}\\]Note:\\(se(\\hat{\\beta}_1)\\) read standard error \\(\\hat{\\beta}_1\\). standard error estimator essentially sample standard deviation estimator, measures spread estimator.\\(se(\\hat{\\beta}_1)\\) read standard error \\(\\hat{\\beta}_1\\). standard error estimator essentially sample standard deviation estimator, measures spread estimator.\\(t_{n-2}\\) distribution read \\(t\\) distribution \\(n-2\\) degrees freedom.\\(t_{n-2}\\) distribution read \\(t\\) distribution \\(n-2\\) degrees freedom.","code":""},{"path":"inf.html","id":"testing-regression-coefficients","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"2.2.2 Testing regression coefficients","text":"Hypothesis testing used investigate population parameter different specific value. context SLR, usually want test \\(\\beta_1\\) 0 . \\(\\beta_1 = 0\\), linear relationship variables.general steps hypothesis testing :Step 1: State null alternative hypotheses.Step 2: test statistic calculated using sample, assuming null true. value test statistic measures sample deviates null.Step 3: Make conclusion, using either critical values p-values.previous module, introduced ANOVA \\(F\\) test. SLR, tests slope SLR equation 0 . turns can also perform \\(t\\) test slope. \\(t\\) test slope, null alternative hypotheses :\\[\nH_0: \\beta_1 = 0, H_a: \\beta_1 \\neq 0.\n\\]\ntest statistic \\[\\begin{equation}\nt = \\frac{\\hat{\\beta}_1 - \\text{ value null}}{se(\\hat{\\beta}_1)}\n\\tag{2.8}\n\\end{equation}\\]compared \\(t_{n-2}\\) distribution. Notice (2.8) comes (2.4).Let us go back simulated example saw last module. data 6000 UVa undergraduate students amount time spend studying week (minutes), many courses taking semester (3 4 credit courses).\\(t\\) statistic testing \\(H_0: \\beta_1 = 0, H_a: \\beta_1 \\neq 0\\) reported 255.7412482, can calculated using (2.8): \\(t= \\frac{120.39310 - 0}{0.4707614}\\). reported p-value virtually 0, reject null hypothesis. data support claim linear association study time number courses taken.","code":"\n##create dataframe\ndf<-data.frame(study,courses)\n\n##fit regression\nresult<-lm(study~courses, data=df)\n##look at regression coefficients\nsummary(result)$coefficients##              Estimate Std. Error   t value      Pr(>|t|)\n## (Intercept)  58.44829  1.9218752  30.41211 4.652442e-189\n## courses     120.39310  0.4707614 255.74125  0.000000e+00"},{"path":"inf.html","id":"confidence-intervals-for-regression-coefficients","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"2.3 Confidence Intervals for Regression Coefficients","text":"Confidence intervals (CIs) similar hypothesis testing sense also based distributional properties estimator. CIs may differ use following ways:assessing parameter different specific value.interested exploring plausible range values unknown parameter.CIs hypothesis tests based distributional properties estimator, conclusions consistent (long significance level ).Recall general form CIs:\\[\\begin{equation}\n\\mbox{estimator} \\pm (\\mbox{multiplier} \\times \\mbox{s.e estimator}).\n\\tag{2.9}\n\\end{equation}\\]following components CIestimator (statistic): numerical quantity describes samplemultiplier: determined confidence level relevant probability distributionstandard error estimator: measure variance estimator (basically square root variance estimator)Following (2.9) (2.4), \\(100(1-\\alpha)\\%\\) CI \\(\\beta_1\\) \\[\\begin{equation}\n\\hat{\\beta}_1 \\pm t_{1-\\alpha/2;n-2}  se(\\hat{\\beta}_1) = \\hat{\\beta}_1 \\pm t_{1-\\alpha/2;n-2} \\frac{s}{\\sqrt{\\sum(x_i - \\bar{x})^{2}}}.\n\\tag{2.10}\n\\end{equation}\\]Going back study time example, 95% CI \\(\\beta_1\\) (119.470237, 121.3159601).interpretation CI 95% confidence true slope \\(\\beta_1\\) lies (119.470237, 121.3159601). words, additional course taken, predicted study time increases 119.470237 121.3159601 minutes.","code":"\n##CI for coefficients\nconfint(result,level = 0.95)[2,]##    2.5 %   97.5 % \n## 119.4702 121.3160"},{"path":"inf.html","id":"thought-questions","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"2.3.1 Thought questions","text":"conclusion 95% CI consistent hypothesis test \\(H_0: \\beta_1 = 0\\) previous section 0.05 significance level?conclusion 95% CI consistent hypothesis test \\(H_0: \\beta_1 = 0\\) previous section 0.05 significance level?presented hypothesis tests CIs slope, \\(\\beta_1\\).\ncalculate \\(t\\) statistic wanted test \\(H_0: \\beta_0 = 0, H_0: \\beta_0 \\neq 0\\)?\ncalculate 95% CI intercept \\(\\beta_0\\)?\npresented hypothesis tests CIs slope, \\(\\beta_1\\).calculate \\(t\\) statistic wanted test \\(H_0: \\beta_0 = 0, H_0: \\beta_0 \\neq 0\\)?calculate \\(t\\) statistic wanted test \\(H_0: \\beta_0 = 0, H_0: \\beta_0 \\neq 0\\)?calculate 95% CI intercept \\(\\beta_0\\)?calculate 95% CI intercept \\(\\beta_0\\)?Generally, usually interested slope intercept.","code":""},{"path":"inf.html","id":"ci-of-the-mean-response","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"2.4 CI of the Mean Response","text":"established least squares estimators \\(\\hat{\\beta}_1,\\hat{\\beta}_0\\) associated variances. Since estimated SLR equation \\[\\begin{equation}\n\\hat{y}=\\hat{\\beta}_0+\\hat{\\beta}_1 x,\n\\tag{2.11}\n\\end{equation}\\]stands reason \\(\\hat{y}\\) associated variance well, since function \\(\\hat{\\beta}_1,\\hat{\\beta}_0\\).two interpretations \\(\\hat{y}\\):estimates mean \\(y\\) \\(x=x_0\\);predicts value \\(y\\) new observation \\(x=x_0\\).Note: \\(x_0\\) denotes specific numerical value predictor variable.Depending interpretation want, two different intervals based \\(\\hat{y}\\). first interpretation associated confidence interval mean response, \\(\\hat{\\mu}_{y|x_0}\\), given predictor. used interested average value response variable, predictor equal specific value. CI \\[\\begin{equation}\n\\hat{\\mu}_{y|x_0}\\pm t_{1-\\alpha/2,n-2}s\\sqrt{\\frac{1}{n} +\n\\frac{(x_0-\\bar{x})^2}{\\sum(x_i-\\bar{x})^2}}.\n\\tag{2.12}\n\\end{equation}\\]Going back study time example, suppose want average study time students take 5 courses, 95% CI isWe 95% confidence average study time students take 5 courses 659.2223688 661.605187 minutes.","code":"\n##CI for mean y when x=5\nnewdata<-data.frame(courses=5)\npredict(result, newdata, level=0.95, interval=\"confidence\")##        fit      lwr      upr\n## 1 660.4138 659.2224 661.6052"},{"path":"inf.html","id":"pi-of-a-new-response","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"2.5 PI of a New Response","text":"Previously, found CI mean \\(y\\) given specific value \\(x\\), (2.12). CI gives us idea location regression line specific \\(x\\).Instead, may interest finding interval new value \\(\\hat{y}_0\\), new observation \\(x=x_0\\). called prediction interval (PI) future observation \\(y_0\\) predictor specific value. interval follows second interpretation \\(\\hat{y}\\).PI \\(\\hat{y}_0\\) takes account:Variation location distribution \\(y\\) (.e. center distribution \\(y\\)?).Variation within probability distribution \\(y\\).comparison, confidence interval mean response (2.12) takes account first element. PI \\[\\begin{equation}\n\\hat{y}_0\\pm t_{1-\\alpha/2,n-2}s \\sqrt{1+\\frac{1}{n} +\n\\frac{(x_0-\\bar{x})^2}{\\sum(x_i-\\bar{x})^2}}.\n\\tag{2.13}\n\\end{equation}\\]Going back study time example, suppose newly enrolled student wishes take 5 courses, student wants predict study timeWe 95% confidence study time student 602.0347305 718.7928253 minutes.","code":"\n##PI for y when x=5\npredict(result, newdata, level=0.95, interval=\"prediction\")##        fit      lwr      upr\n## 1 660.4138 602.0347 718.7928"},{"path":"inf.html","id":"thought-questions-1","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"2.5.1 Thought questions","text":"following two scenarios, decide interested CI mean response given predictor (2.12), PI future response given predictor (2.13).\nwish estimate waiting time, average, DMV customers 10 people line DMV.\nenter DMV notice 10 people line. want estimate waiting time.\nfollowing two scenarios, decide interested CI mean response given predictor (2.12), PI future response given predictor (2.13).wish estimate waiting time, average, DMV customers 10 people line DMV.wish estimate waiting time, average, DMV customers 10 people line DMV.enter DMV notice 10 people line. want estimate waiting time.enter DMV notice 10 people line. want estimate waiting time.Look standard errors associated intervals given (2.12) (2.13). related ?Look standard errors associated intervals given (2.12) (2.13). related ?","code":""},{"path":"inf.html","id":"supplemental-notes-on-statistical-inference","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"2.6 Supplemental Notes on Statistical Inference","text":"","code":""},{"path":"inf.html","id":"hypothesis-statements","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"2.6.1 Hypothesis statements","text":"Let’s consider \\(t\\) test regression parameter, \\(\\beta_1\\). Depending context, following null alternative hypotheses\\(H_0: \\beta_1 = 0, H_a: \\beta_1 \\neq 0\\).\\(H_0: \\beta_1 = 0, H_a: \\beta_1 > 0\\).\\(H_0: \\beta_1 = 0, H_a: \\beta_1 < 0\\).null hypothesis stated statement equality. concept holds true hypothesis tests general. books / resources might state \\(H_0: \\beta_1 = 0, H_a: \\beta_1 \\neq 0\\).\\(H_0: \\beta_1 \\leq 0, H_a: \\beta_1 > 0\\).\\(H_0: \\beta_1 \\geq 0, H_a: \\beta_1 < 0\\).prefer using equality statement null hypothesis following reasons (theoretical, pedagogical, practical):null hypothesis equality aligns definition p-value.p-value probability observing sample estimate (value extreme), null hypothesis true (.e. \\(\\beta_1\\) truly 0). assuming calculation test statistic.People tend get confused null alternative hypotheses involve inequalities (alternative hypothesis trying support).Conclusions made terms supporting (supporting) alternative hypothesis.","code":""},{"path":"inf.html","id":"sample-size-and-statistical-inference","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"2.6.2 Sample size and statistical inference","text":"Generally speaking, relationship sample size statistical inference (assuming characteristics remain sample randomly obtained representative population interest):Larger sample sizes (typically) lead narrower confidence intervals (precise intervals).Sample estimates based larger samples likely closer true parameters.Larger sample (typically) lead evidence null hypothesis.\nmeans larger sample size leads powerful test. power test probability hypothesis test able correctly reject null hypothesis.\nmeans larger sample size leads powerful test. power test probability hypothesis test able correctly reject null hypothesis.","code":""},{"path":"inf.html","id":"small-sample-sizes","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"2.6.2.1 Small sample sizes","text":"Small sample sizes tend result :Confidence intervals wide.Sample estimates likely away true parameters.Hypothesis tests likely incorrectly fail reject null hypothesis alternative hypothesis true.larger sample sizes advantages, also disadvantages sample sizes extremely large.","code":""},{"path":"inf.html","id":"large-sample-sizes","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"2.6.2.2 Large sample sizes","text":"“statistically significant” result necessarily mean result practical consequences. Suppose 95% confidence interval \\(\\beta_1\\) \\((0.001, 0.002)\\). interval excludes 0, “statistically significantly” different 0 (!), result practical consequences? narrow CI barely excludes null value can happen large sample size.one conduct corresponding hypothesis test, reject null hypothesis \\(\\beta_1 = 0\\). large sample sizes, hypothesis tests sensitive small departures null hypothesis.instances, may worth considering hypothesis tests involving different value null hypothesis, one makes sense question. example, practically significant slope may need greater specific numerical value certain context.Statistical inference assess statistical significance.Subject area knowledge assess practical significance.","code":""},{"path":"inf.html","id":"questions","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"2.6.2.3 Questions","text":"following results statistically significant? , results also practically significant? Assume two-sided test null value 0 (made examples):assessing studying associated better test scores, SLR carried test scores (100 points) study time (hours). 95% confidence interval slope \\(\\beta_1\\) (5.632, 7.829).assessing studying associated better test scores, SLR carried test scores (100 points) study time (hours). 95% confidence interval slope \\(\\beta_1\\) (5.632, 7.829).SLR carried explore linear relationship number years school income (thousands dollars). 95% confidence interval slope \\(\\beta_1\\) (0.051, 0.243).SLR carried explore linear relationship number years school income (thousands dollars). 95% confidence interval slope \\(\\beta_1\\) (0.051, 0.243).","code":""},{"path":"inf.html","id":"cautions-using-slr-and-correlation","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"2.6.3 Cautions using SLR and Correlation","text":"Simple linear regression correlation meant assessing linear relationships. relationship linear, need transform variable(s) (transformed variables linear relationship. explore Module ??).Always verify via scatterplot relationship least approximately linear.high correlation significant estimated slope prove strong linear relationship variables. Conversely, correlation close 0 insignificant estimated slope also proof relationship variables.","code":""},{"path":"inf.html","id":"outliers","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"2.6.3.1 Outliers","text":"SLR correlation sensitive outliers / influential observations. Generally speaking, data “far away” different rest observations. data points can visually inspected scatterplot. potential considerations dealing data points:Investigate observations. usually something making ``stand ” rest data.Data entry errors can corrected. sure mention report.Revisit data sampled. Perhaps data point part population interest. , data point can removed (legitimate), sure mention report.regards regression analysis:Exclusion data points must clearly documented.Fit regression without data points question, see similar different conclusions become.data points large value(s) predictor /response, log transformation variable can pull large values.Consider subsetting data create separate models subset; focus subset make clear analysis subset.Knowing data context can help lot decisions.","code":""},{"path":"inf.html","id":"association-and-causation","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"2.6.3.2 Association and causation","text":"Two correlated variables mean one variable causes variable change. example, consider plot ice cream consumption deaths drowning various months. may positive correlation, clearly, eating ice cream cause drownings. correlation can explained third (lurking) variable: weather.lurking variable variable impact relationship variables studied, studied.carefully designed randomized experiment can control lurking variables, causal relationships can established. Typically, experiments include:control group treatment group.Random assignment large number observations treatment control groups. Due random assignment, general characteristics subjects group similar.Lurking variables always issue observational studies. Researchers observational studies intervene observations simply observe data observations generate. Causal relationships much difficult establish observational studies.","code":""},{"path":"inf.html","id":"questions-1","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"2.6.3.3 Questions","text":"Consider palmerpenguins dataset working . data contain size measurements three different species penguins three islands Palmer Archipelago, Antarctica three years. observational study randomized experiment?Consider palmerpenguins dataset working . data contain size measurements three different species penguins three islands Palmer Archipelago, Antarctica three years. observational study randomized experiment?fertilizer company wishes evaluate effective new fertilizer terms improving yield crops. large field divided many smaller plots, smaller plot randomly assigned receive either new fertilizer standard fertilizer. observational study randomized experiment?fertilizer company wishes evaluate effective new fertilizer terms improving yield crops. large field divided many smaller plots, smaller plot randomly assigned receive either new fertilizer standard fertilizer. observational study randomized experiment?professor wishes evaluate effectiveness various teaching methods (traditional vs flipped classroom). professor uses traditional approach section meets Mondays, Wednesdays, Fridays 9 10am uses flipped classroom approach section meets Mondays, Wednesdays, Fridays 2 3pm. Students free choose whichever section wanted register , knowledge teaching method used. potential lurking variables study?professor wishes evaluate effectiveness various teaching methods (traditional vs flipped classroom). professor uses traditional approach section meets Mondays, Wednesdays, Fridays 9 10am uses flipped classroom approach section meets Mondays, Wednesdays, Fridays 2 3pm. Students free choose whichever section wanted register , knowledge teaching method used. potential lurking variables study?","code":""},{"path":"inf.html","id":"r-tutorial-1","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"2.7 R Tutorial","text":"tutorial, continue work dataset elmhurst openintro package R.key pieces information :random sample 50 students (freshman 2011 class Elmhurst College).Family income student (units missing).Gift aid, $1000s.want explore family income may related gift aid, simple linear regression framework.","code":"\nlibrary(tidyverse)\nlibrary(openintro)\nData<-openintro::elmhurst"},{"path":"inf.html","id":"hypothesis-test-for-beta_1-and-beta_0","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"Hypothesis test for \\(\\beta_1\\) (and \\(\\beta_0\\))","text":"Applying summary() function lm() gives results hypothesis tests \\(\\beta_1\\) \\(\\beta_0\\):coefficients, can see results hypothesis tests \\(\\beta_1\\) \\(\\beta_0\\). Specifically, \\(\\beta_1\\):\\(\\hat{\\beta}_1\\) = -0.0430717\\(se(\\hat{\\beta}_1)\\) = 0.0108095the test statistic \\(t\\) = -3.984621the corresponding p-value 2.2887345^{-4}can work p-value using R (slight difference due rounding):find critical value using R:Either way, end rejecting null hypothesis. data support claim linear association gift aid family income.Note:\\(t\\) tests regression coefficients based \\(H_0: \\beta_j = 0, H_a: \\beta_j \\neq 0\\). reported p-value based set null alternative hypotheses. null alternative hypotheses different, need compute test statistic p-value.\\(t\\) tests regression coefficients based \\(H_0: \\beta_j = 0, H_a: \\beta_j \\neq 0\\). reported p-value based set null alternative hypotheses. null alternative hypotheses different, need compute test statistic p-value.SLR, two-sided \\(t\\) test \\(\\beta_1\\) gives exact result ANOVA \\(F\\) test. Notice p-values . \\(F\\) statistic \\(15.88\\) squared \\(t\\) statistic, \\((-3.985)^2\\).SLR, two-sided \\(t\\) test \\(\\beta_1\\) gives exact result ANOVA \\(F\\) test. Notice p-values . \\(F\\) statistic \\(15.88\\) squared \\(t\\) statistic, \\((-3.985)^2\\).","code":"\n##Fit a regression model\nresult<-lm(gift_aid~family_income, data=Data)\n\n##look at t stats and F stat\nsummary(result)## \n## Call:\n## lm(formula = gift_aid ~ family_income, data = Data)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -10.1128  -3.6234  -0.2161   3.1587  11.5707 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)   24.31933    1.29145  18.831  < 2e-16 ***\n## family_income -0.04307    0.01081  -3.985 0.000229 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 4.783 on 48 degrees of freedom\n## Multiple R-squared:  0.2486, Adjusted R-squared:  0.2329 \n## F-statistic: 15.88 on 1 and 48 DF,  p-value: 0.0002289\n##pvalue\n2*pt(-abs(-3.985), df = 50-2)## [1] 0.0002285996\n##critical value\nqt(1-0.05/2, df = 50-2)## [1] 2.010635"},{"path":"inf.html","id":"confidence-interval-for-beta_1-and-beta_0","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"Confidence interval for \\(\\beta_1\\) (and \\(\\beta_0\\))","text":"find 95% confidence intervals coefficients, use confint() function:95% CI \\(\\beta_1\\) (-0.0648056, -0.0213378). 95% confidence additional thousand dollars family income, predicted gift aid decreases $21.3378 $64.8056.","code":"\n##to produce 95% CIs for all regression coefficients\nconfint(result,level = 0.95)##                     2.5 %      97.5 %\n## (Intercept)   21.72269421 26.91596380\n## family_income -0.06480555 -0.02133775"},{"path":"inf.html","id":"confidence-interval-for-mean-response-for-given-x","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"Confidence interval for mean response for given x","text":"Suppose want confidence interval average gift aid Elmhurst College students family income 80 thousand dollars. can use predict() function:95% CI mean gift aid students family income 80 thousand dollars (19.4336609, 22.3135327). 95% confidence mean gift aid students family income 80 thousand dollars $19 433.66 $22 313.53.","code":"\n##to produce 95% CI for the mean response when x=80, \nnewdata<-data.frame(family_income=80)\npredict(result,newdata,level=0.95, interval=\"confidence\")##       fit      lwr      upr\n## 1 20.8736 19.43366 22.31353"},{"path":"inf.html","id":"prediction-interval-for-a-response-for-a-given-x","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"Prediction interval for a response for a given x","text":"prediction interval gift aid Elmhurst College student family income 80 thousand dollars:95% confidence Elmhurst College student family income 80, student’s gift aid $11 150.32 $30 596.87.","code":"\n##and the 95% PI for the response of an observation when x=80\npredict(result,newdata,level=0.95, interval=\"prediction\")##       fit      lwr      upr\n## 1 20.8736 11.15032 30.59687"},{"path":"inf.html","id":"visualization-of-ci-for-mean-response-given-x-and-pi-of-response-given-x","chapter":"2 Inference with Simple Linear Regression (SLR)","heading":"Visualization of CI for mean response given x and PI of response given x","text":"using ggplot() function create scatterplot, can overlay SLR equation adding layer via geom_smooth(method = lm). default, CI mean response value predictor gets overlaid well. previous tutorial, removed adding se=FALSE inside geom_smooth():Overlaying prediction intervals require bit work. need compute lower upper bounds PI value predictor:Previously, used predict() function, provided numerical value \\(x\\) make prediction . supplied, function use current values \\(x\\) make predictions, actually print warning message. purpose, issue since exactly want.add preds data frame order overlay lower upper bounds scatterplot, adding extra layers via geom_line() ggplot() function:mentioned notes, CI captures location regression line, whereas PI captures data points.","code":"\n##regular scatterplot\n##with regression line overlaid, and bounds of CI for mean y\nggplot2::ggplot(Data, aes(x=family_income, y=gift_aid))+\n  geom_point() +\n  geom_smooth(method=lm)+\n  labs(x=\"Family Income\", \n       y=\"Gift Aid\", \n       title=\"Scatterplot of Gift Aid against Family Income\")## `geom_smooth()` using formula = 'y ~ x'\n##find PIs for each observation\npreds <- predict(result, interval=\"prediction\")## Warning in predict.lm(result, interval = \"prediction\"): predictions on current data refer to _future_ responses\n##add preds to data frame\nData<-data.frame(Data,preds)\n\n##overlay PIs via geom_line()\nggplot2::ggplot(Data, aes(x=family_income, y=gift_aid))+\n  geom_point() +\n  geom_line(aes(y=lwr), color = \"red\", linetype = \"dashed\")+\n  geom_line(aes(y=upr), color = \"red\", linetype = \"dashed\")+\n  geom_smooth(method=lm)+\n  labs(x=\"Family Income\", \n       y=\"Gift Aid\", \n       title=\"Scatterplot of Gift Aid against Family Income\")## `geom_smooth()` using formula = 'y ~ x'"}]
