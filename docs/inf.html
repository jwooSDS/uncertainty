<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 2 Inference with Simple Linear Regression (SLR) | Linear Models for Data Science</title>
<meta name="author" content="Jeffrey Woo">
<meta name="description" content="2.1 Introduction Oftentimes, the data we collect come from a random sample that is representative of the population of interest. A common example is an election poll before a presidential...">
<meta name="generator" content="bookdown 0.43 with bs4_book()">
<meta property="og:title" content="Chapter 2 Inference with Simple Linear Regression (SLR) | Linear Models for Data Science">
<meta property="og:type" content="book">
<meta property="og:description" content="2.1 Introduction Oftentimes, the data we collect come from a random sample that is representative of the population of interest. A common example is an election poll before a presidential...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 2 Inference with Simple Linear Regression (SLR) | Linear Models for Data Science">
<meta name="twitter:description" content="2.1 Introduction Oftentimes, the data we collect come from a random sample that is representative of the population of interest. A common example is an election poll before a presidential...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.9.0/transition.js"></script><script src="libs/bs3compat-0.9.0/tabs.js"></script><script src="libs/bs3compat-0.9.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Linear Models for Data Science</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="slr.html"><span class="header-section-number">1</span> Basics with Simple Linear Regression (SLR)</a></li>
<li><a class="active" href="inf.html"><span class="header-section-number">2</span> Inference with Simple Linear Regression (SLR)</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="inf" class="section level1" number="2">
<h1>
<span class="header-section-number">2</span> Inference with Simple Linear Regression (SLR)<a class="anchor" aria-label="anchor" href="#inf"><i class="fas fa-link"></i></a>
</h1>
<div id="introduction" class="section level2" number="2.1">
<h2>
<span class="header-section-number">2.1</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction"><i class="fas fa-link"></i></a>
</h2>
<p>Oftentimes, the data we collect come from a random sample that is representative of the population of interest. A common example is an election poll before a presidential election. Random sampling allows the sample to be representative of the population. However, if we obtain another random sample, the characteristics of the new sample are unlikely to be exactly the same as the first sample. For example, the sample proportion who will vote for a certain party is unlikely to be the same for both random samples. What this tells us is that even with representative samples, sample proportions are unlikely to be equal to the population proportion, and sample proportions vary from sample to sample.</p>
<p>Dr. W. Edwards Deming’s Red Bead experiment illustrates this concept. A video of this experiment <a href="https://www.youtube.com/watch?v=R3ewHrpqclA">can be found here.</a></p>
<p>In this video, the number of red beads, which represent bad products, varies each time the worker obtains a random sample of 50 beads. The fact that the number of red beads increases in his second sample does not indicate that he performed his task any worse, as this increase is due to the random variation associated with samples.</p>
<p>Note: Deming’s Red Bead experiment was developed to illustrate concepts associated with management. He is best known for his work in developing the Japanese economy after World War II. You will be able to find many blogs/articles discussing the experiment on the World Wide Web. Although many of the articles discuss how this experiment applies in management, it can be used to illustrate concepts of variation.</p>
<p>The same idea extends to the slope and intercept of a regression line. The estimated slope and intercept will vary from sample to sample and are unlikely to be equal to the population slope and intercept. In inferential statistics, we use hypothesis tests and confidence intervals to aid us in accounting for this random variation. In this module, you will learn how to account for and quantify the random variation associated with the estimated regression model, and how to interpret the estimated regression model while accounting for random variation.</p>
<div id="review-from-previous-module" class="section level3" number="2.1.1">
<h3>
<span class="header-section-number">2.1.1</span> Review from previous module<a class="anchor" aria-label="anchor" href="#review-from-previous-module"><i class="fas fa-link"></i></a>
</h3>
<p>The <strong>simple linear regression model</strong> is written as</p>
<p><span class="math display" id="eq:4SLRmod">\[\begin{equation}
y=\beta_0+\beta_{1} x + \epsilon.
\tag{2.1}
\end{equation}\]</span></p>
<p>We make some assumptions for the error term <span class="math inline">\(\epsilon\)</span>. They are:</p>
<ol style="list-style-type: decimal">
<li>The errors have mean 0.</li>
<li>The <strong>errors have variance denoted by <span class="math inline">\(\sigma^2\)</span></strong>. Notice this variance is constant.</li>
<li>The errors are independent.</li>
<li>The errors are normally distributed.</li>
</ol>
<p>These assumptions allow us to derive the distributional properties associated with our least squares estimators <span class="math inline">\(\hat{\beta}_0, \hat{\beta}_1\)</span>, which then enables us to compute reliable confidence intervals and perform hypothesis tests on our SLR reliably.</p>
<p><span class="math inline">\(\hat{\beta}_1,\hat{\beta}_0\)</span> are the estimators for <span class="math inline">\(\beta_1,\beta_0\)</span> respectively. These estimators can be interpreted in the following manner:</p>
<ul>
<li><strong><span class="math inline">\(\hat{\beta}_1\)</span> denotes the change in the predicted <span class="math inline">\(y\)</span> when <span class="math inline">\(x\)</span> increases by 1 unit. Alternatively, it denotes the change in <span class="math inline">\(y\)</span>, on average, when <span class="math inline">\(x\)</span> increases by 1 unit.</strong></li>
<li><strong><span class="math inline">\(\hat{\beta}_0\)</span> denotes the predicted <span class="math inline">\(y\)</span> when <span class="math inline">\(x=0\)</span>. Alternatively, it denotes the average of <span class="math inline">\(y\)</span> when <span class="math inline">\(x=0\)</span>.</strong></li>
</ul>
<p>How do the values of these estimators vary from sample to sample?</p>
</div>
</div>
<div id="hypothesis-testing-in-slr" class="section level2" number="2.2">
<h2>
<span class="header-section-number">2.2</span> Hypothesis Testing in SLR<a class="anchor" aria-label="anchor" href="#hypothesis-testing-in-slr"><i class="fas fa-link"></i></a>
</h2>
<div id="distribution-of-least-squares-estimators" class="section level3" number="2.2.1">
<h3>
<span class="header-section-number">2.2.1</span> Distribution of least squares estimators<a class="anchor" aria-label="anchor" href="#distribution-of-least-squares-estimators"><i class="fas fa-link"></i></a>
</h3>
<p><strong>Gauss Markov Theorem</strong>: Under assumptions for a regression model, the least squares estimators <span class="math inline">\(\hat{\beta}_1\)</span> and <span class="math inline">\(\hat{\beta}_0\)</span> are unbiased and have minimum variance among all unbiased linear estimators.</p>
<p>Thus, the least squares estimators have the following properties:</p>
<ol style="list-style-type: decimal">
<li>
<span class="math inline">\(\mbox{E}(\hat{\beta}_1) = \beta_1\)</span>, <span class="math inline">\(\mbox{E}(\hat{\beta}_0) = \beta_0\)</span>
</li>
</ol>
<p>Note: An estimator is <strong>unbiased</strong> if its expected value is exactly equal to the parameter it is estimating.</p>
<ol start="2" style="list-style-type: decimal">
<li>The variance of <span class="math inline">\(\hat{\beta}_1\)</span> is</li>
</ol>
<p><span class="math display" id="eq:4varb1">\[\begin{equation}
\mbox{Var}(\hat{\beta}_1) = \frac{\sigma^{2}}{\sum{(x_{i}-\bar{x})^{2}}}
\tag{2.2}
\end{equation}\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>The variance of <span class="math inline">\(\hat{\beta}_0\)</span> is</li>
</ol>
<p><span class="math display" id="eq:4varb0">\[\begin{equation}
\mbox{Var}(\hat{\beta}_0) = \sigma^2 \left[\frac{1}{n} + \frac{\bar{x}^2}{\sum (x_i -\bar{x})^2}\right]
\tag{2.3}
\end{equation}\]</span></p>
<ol start="4" style="list-style-type: decimal">
<li>
<span class="math inline">\(\hat{\beta}_1\)</span> and <span class="math inline">\(\hat{\beta}_0\)</span> both follow a normal distribution.</li>
</ol>
<p>Note that in <a href="inf.html#eq:4varb1">(2.2)</a> and <a href="inf.html#eq:4varb0">(2.3)</a>, we use <span class="math inline">\(s^2 = MS_{res}\)</span> to estimate <span class="math inline">\(\sigma^2\)</span> since <span class="math inline">\(\sigma^2\)</span> is a unknown value.</p>
<p>What these imply is that if we standardize <span class="math inline">\(\hat{\beta}_1\)</span> and <span class="math inline">\(\hat{\beta}_0\)</span>, these standardized quantities will follow a <span class="math inline">\(t_{n-2}\)</span> distribution, i.e.</p>
<p><span class="math display" id="eq:distb1">\[\begin{equation}
\frac{\hat{\beta}_1 - \beta_1}{se(\hat{\beta}_1)}\sim t_{n-2}
\tag{2.4}
\end{equation}\]</span></p>
<p>and</p>
<p><span class="math display" id="eq:distb0">\[\begin{equation}
\frac{\hat{\beta}_0 - \beta_0}{se(\hat{\beta}_0)}\sim t_{n-2},
\tag{2.5}
\end{equation}\]</span></p>
<p>where</p>
<p><span class="math display" id="eq:seb1">\[\begin{equation}
se(\hat{\beta}_1) = \sqrt{\frac{MS_{res}}{\sum{(x_{i}-\bar{x})^{2}}}} = \frac{s}{\sqrt{\sum{(x_{i}-\bar{x})^{2}}}}
\tag{2.6}
\end{equation}\]</span></p>
<p>and</p>
<p><span class="math display" id="eq:seb0">\[\begin{equation}
se(\hat{\beta}_0) = \sqrt{MS_{res}\left[\frac{1}{n} + \frac{\bar{x}^2}{\sum (x_i -\bar{x})^2}\right]} = s \sqrt{\frac{1}{n} + \frac{\bar{x}^2}{\sum (x_i -\bar{x})^2}}
\tag{2.7}
\end{equation}\]</span></p>
<p>Note:</p>
<ul>
<li><p><span class="math inline">\(se(\hat{\beta}_1)\)</span> is read as the <strong>standard error of <span class="math inline">\(\hat{\beta}_1\)</span></strong>. The standard error of any estimator is essentially the sample standard deviation of that estimator, and measures the spread of that estimator.</p></li>
<li><p>A <span class="math inline">\(t_{n-2}\)</span> distribution is read as a <strong><span class="math inline">\(t\)</span> distribution with <span class="math inline">\(n-2\)</span> degrees of freedom</strong>.</p></li>
</ul>
</div>
<div id="testing-regression-coefficients" class="section level3" number="2.2.2">
<h3>
<span class="header-section-number">2.2.2</span> Testing regression coefficients<a class="anchor" aria-label="anchor" href="#testing-regression-coefficients"><i class="fas fa-link"></i></a>
</h3>
<p>Hypothesis testing is used to investigate if a population parameter is <strong>different from a specific value</strong>. In the context of SLR, we usually want to test if <span class="math inline">\(\beta_1\)</span> is 0 or not. If <span class="math inline">\(\beta_1 = 0\)</span>, there is no linear relationship between the variables.</p>
<p>The general steps in hypothesis testing are:</p>
<ul>
<li>Step 1: State the null and alternative hypotheses.</li>
<li>Step 2: A test statistic is calculated using the sample, assuming the null is true. The value of the test statistic measures how the <strong>sample deviates from the null</strong>.</li>
<li>Step 3: Make conclusion, using either critical values or p-values.</li>
</ul>
<p>In the previous module, we introduced the ANOVA <span class="math inline">\(F\)</span> test. In SLR, this tests if the slope of the SLR equation is 0 or not. It turns out that we can also perform a <span class="math inline">\(t\)</span> test for the slope. In the <span class="math inline">\(t\)</span> test for the slope, the null and alternative hypotheses are:</p>
<p><span class="math display">\[
H_0: \beta_1 = 0, H_a: \beta_1 \neq 0.
\]</span>
The test statistic is</p>
<p><span class="math display" id="eq:4ttest">\[\begin{equation}
t = \frac{\hat{\beta}_1 - \text{ value in null}}{se(\hat{\beta}_1)}
\tag{2.8}
\end{equation}\]</span></p>
<p>which is compared with a <span class="math inline">\(t_{n-2}\)</span> distribution. Notice that <a href="inf.html#eq:4ttest">(2.8)</a> comes from <a href="inf.html#eq:distb1">(2.4)</a>.</p>
<p>Let us go back to our simulated example that we saw in the last module. We have data from 6000 UVa undergraduate students on the amount of time they spend studying in a week (in minutes), and how many courses they are taking in the semester (3 or 4 credit courses).</p>
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##create dataframe</span></span>
<span><span class="va">df</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">study</span>,<span class="va">courses</span><span class="op">)</span></span>
<span></span>
<span><span class="co">##fit regression</span></span>
<span><span class="va">result</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">study</span><span class="op">~</span><span class="va">courses</span>, data<span class="op">=</span><span class="va">df</span><span class="op">)</span></span>
<span><span class="co">##look at regression coefficients</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span></span></code></pre></div>
<pre><code>##              Estimate Std. Error   t value      Pr(&gt;|t|)
## (Intercept)  58.44829  1.9218752  30.41211 4.652442e-189
## courses     120.39310  0.4707614 255.74125  0.000000e+00</code></pre>
<p>The <span class="math inline">\(t\)</span> statistic for testing <span class="math inline">\(H_0: \beta_1 = 0, H_a: \beta_1 \neq 0\)</span> is reported to be 255.7412482, which can be calculated using <a href="inf.html#eq:4ttest">(2.8)</a>: <span class="math inline">\(t= \frac{120.39310 - 0}{0.4707614}\)</span>. The reported p-value is virtually 0, so we reject the null hypothesis. The data support the claim that there is a linear association between study time and the number of courses taken.</p>
</div>
</div>
<div id="confidence-intervals-for-regression-coefficients" class="section level2" number="2.3">
<h2>
<span class="header-section-number">2.3</span> Confidence Intervals for Regression Coefficients<a class="anchor" aria-label="anchor" href="#confidence-intervals-for-regression-coefficients"><i class="fas fa-link"></i></a>
</h2>
<p>Confidence intervals (CIs) are similar to hypothesis testing in the sense that they are also based on the distributional properties of an estimator. CIs may differ in their use in the following ways:</p>
<ol style="list-style-type: decimal">
<li>We are not assessing if the parameter is different from a specific value.</li>
<li>We are more interested in exploring a plausible <strong>range of values for an unknown parameter</strong>.</li>
</ol>
<p>Because CIs and hypothesis tests are based on the distributional properties of an estimator, their conclusions will be consistent (as long as the significance level is the same).</p>
<p>Recall the general form for CIs:</p>
<p><span class="math display" id="eq:4CI">\[\begin{equation}
\mbox{estimator} \pm (\mbox{multiplier} \times \mbox{s.e of estimator}).
\tag{2.9}
\end{equation}\]</span></p>
<p>We have the following components of a CI</p>
<ul>
<li>
<strong>estimator (or statistic)</strong>: numerical quantity that describes a sample</li>
<li>
<strong>multiplier</strong>: determined by confidence level and relevant probability distribution</li>
<li>
<strong>standard error of estimator</strong>: measure of variance of estimator (basically the square root of the variance of estimator)</li>
</ul>
<p>Following <a href="inf.html#eq:4CI">(2.9)</a> and <a href="inf.html#eq:distb1">(2.4)</a>, the <span class="math inline">\(100(1-\alpha)\%\)</span> CI for <span class="math inline">\(\beta_1\)</span> is</p>
<p><span class="math display" id="eq:4CIb1">\[\begin{equation}
\hat{\beta}_1 \pm t_{1-\alpha/2;n-2}  se(\hat{\beta}_1) = \hat{\beta}_1 \pm t_{1-\alpha/2;n-2} \frac{s}{\sqrt{\sum(x_i - \bar{x})^{2}}}.
\tag{2.10}
\end{equation}\]</span></p>
<p>Going back to our study time example, the 95% CI for <span class="math inline">\(\beta_1\)</span> is (119.470237, 121.3159601).</p>
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##CI for coefficients</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html">confint</a></span><span class="op">(</span><span class="va">result</span>,level <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span></span></code></pre></div>
<pre><code>##    2.5 %   97.5 % 
## 119.4702 121.3160</code></pre>
<p>An interpretation of this CI is that we have 95% confidence that the true slope <span class="math inline">\(\beta_1\)</span> lies between (119.470237, 121.3159601). In other words, for each additional course taken, the predicted study time increases between 119.470237 and 121.3159601 minutes.</p>
<div id="thought-questions" class="section level3" number="2.3.1">
<h3>
<span class="header-section-number">2.3.1</span> Thought questions<a class="anchor" aria-label="anchor" href="#thought-questions"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li><p>Is the conclusion from this 95% CI consistent with the hypothesis test for <span class="math inline">\(H_0: \beta_1 = 0\)</span> in the previous section at 0.05 significance level?</p></li>
<li>
<p>I have presented hypothesis tests and CIs for the slope, <span class="math inline">\(\beta_1\)</span>.</p>
<ul>
<li><p>How would you calculate the <span class="math inline">\(t\)</span> statistic if you wanted to test <span class="math inline">\(H_0: \beta_0 = 0, H_0: \beta_0 \neq 0\)</span>?</p></li>
<li><p>How would you calculate the 95% CI for the intercept <span class="math inline">\(\beta_0\)</span>?</p></li>
</ul>
</li>
</ul>
<p>Generally, we are usually more interested in the slope than the intercept.</p>
</div>
</div>
<div id="ci-of-the-mean-response" class="section level2" number="2.4">
<h2>
<span class="header-section-number">2.4</span> CI of the Mean Response<a class="anchor" aria-label="anchor" href="#ci-of-the-mean-response"><i class="fas fa-link"></i></a>
</h2>
<p>We have established that the least squares estimators <span class="math inline">\(\hat{\beta}_1,\hat{\beta}_0\)</span> have their associated variances. Since the estimated SLR equation is</p>
<p><span class="math display" id="eq:4fitted">\[\begin{equation}
\hat{y}=\hat{\beta}_0+\hat{\beta}_1 x,
\tag{2.11}
\end{equation}\]</span></p>
<p>it stands to reason that <span class="math inline">\(\hat{y}\)</span> has an associated variance as well, since it is a function of <span class="math inline">\(\hat{\beta}_1,\hat{\beta}_0\)</span>.</p>
<p>There are two interpretations of <span class="math inline">\(\hat{y}\)</span>:</p>
<ol style="list-style-type: decimal">
<li>it <strong>estimates the mean of <span class="math inline">\(y\)</span> when <span class="math inline">\(x=x_0\)</span></strong>;</li>
<li>it <strong>predicts the value of <span class="math inline">\(y\)</span> for a new observation when <span class="math inline">\(x=x_0\)</span></strong>.</li>
</ol>
<p>Note: <span class="math inline">\(x_0\)</span> denotes a specific numerical value for the predictor variable.</p>
<p>Depending on which interpretation we want, there are two different intervals based on <span class="math inline">\(\hat{y}\)</span>. The first interpretation is associated with the <strong>confidence interval for the mean response, <span class="math inline">\(\hat{\mu}_{y|x_0}\)</span>, given the predictor</strong>. This is used when we are interested in the average value of the response variable, when the predictor is equal to a specific value. This CI is</p>
<p><span class="math display" id="eq:4CImean">\[\begin{equation}
\hat{\mu}_{y|x_0}\pm t_{1-\alpha/2,n-2}s\sqrt{\frac{1}{n} +
\frac{(x_0-\bar{x})^2}{\sum(x_i-\bar{x})^2}}.
\tag{2.12}
\end{equation}\]</span></p>
<p>Going back to our study time example, suppose we want the average study time for students who take 5 courses, the 95% CI is</p>
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##CI for mean y when x=5</span></span>
<span><span class="va">newdata</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>courses<span class="op">=</span><span class="fl">5</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">result</span>, <span class="va">newdata</span>, level<span class="op">=</span><span class="fl">0.95</span>, interval<span class="op">=</span><span class="st">"confidence"</span><span class="op">)</span></span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 660.4138 659.2224 661.6052</code></pre>
<p>We have 95% confidence that the average study time for students who take 5 courses is between 659.2223688 and 661.605187 minutes.</p>
</div>
<div id="pi-of-a-new-response" class="section level2" number="2.5">
<h2>
<span class="header-section-number">2.5</span> PI of a New Response<a class="anchor" aria-label="anchor" href="#pi-of-a-new-response"><i class="fas fa-link"></i></a>
</h2>
<p>Previously, we found a CI for the mean of <span class="math inline">\(y\)</span> given a specific value of <span class="math inline">\(x\)</span>, <a href="inf.html#eq:4CImean">(2.12)</a>. This CI gives us an idea about the location of the regression line at a specific of <span class="math inline">\(x\)</span>.</p>
<p>Instead, we may have interest in finding an interval for a new value of <span class="math inline">\(\hat{y}_0\)</span>, when we have a new observation <span class="math inline">\(x=x_0\)</span>. This is called a <strong>prediction interval (PI) for a future observation <span class="math inline">\(y_0\)</span> when the predictor is a specific value</strong>. This interval follows from the second interpretation of <span class="math inline">\(\hat{y}\)</span>.</p>
<p>The PI for <span class="math inline">\(\hat{y}_0\)</span> takes into account:</p>
<ol style="list-style-type: decimal">
<li>Variation in location for the distribution of <span class="math inline">\(y\)</span> (i.e. where is the center of the distribution of <span class="math inline">\(y\)</span>?).</li>
<li>Variation <strong>within the probability distribution of <span class="math inline">\(y\)</span></strong>.</li>
</ol>
<p>By comparison, the confidence interval for the mean response <a href="inf.html#eq:4CImean">(2.12)</a> only takes into account the first element. The PI is</p>
<p><span class="math display" id="eq:4pred">\[\begin{equation}
\hat{y}_0\pm t_{1-\alpha/2,n-2}s \sqrt{1+\frac{1}{n} +
\frac{(x_0-\bar{x})^2}{\sum(x_i-\bar{x})^2}}.
\tag{2.13}
\end{equation}\]</span></p>
<p>Going back to our study time example, suppose we have a newly enrolled student who wishes to take 5 courses, and the student wants to predict his study time</p>
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##PI for y when x=5</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">result</span>, <span class="va">newdata</span>, level<span class="op">=</span><span class="fl">0.95</span>, interval<span class="op">=</span><span class="st">"prediction"</span><span class="op">)</span></span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 660.4138 602.0347 718.7928</code></pre>
<p>We have 95% confidence that the study time for this student is between 602.0347305 and 718.7928253 minutes.</p>
<div id="thought-questions-1" class="section level3" number="2.5.1">
<h3>
<span class="header-section-number">2.5.1</span> Thought questions<a class="anchor" aria-label="anchor" href="#thought-questions-1"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>
<p>In the following two scenarios, decide if we are more interested in the CI for the mean response given the predictor <a href="inf.html#eq:4CImean">(2.12)</a>, or the PI for a future response given the predictor <a href="inf.html#eq:4pred">(2.13)</a>.</p>
<ul>
<li><p>We wish to estimate the waiting time, on average, of DMV customers if there are 10 people in line at the DMV.</p></li>
<li><p>I enter the DMV and notice 10 people in line. I want to estimate my waiting time.</p></li>
</ul>
</li>
<li><p>Look at the standard errors associated with the intervals given in <a href="inf.html#eq:4CImean">(2.12)</a> and <a href="inf.html#eq:4pred">(2.13)</a>. How are they related to each other?</p></li>
</ul>
</div>
</div>
<div id="supplemental-notes-on-statistical-inference" class="section level2" number="2.6">
<h2>
<span class="header-section-number">2.6</span> Supplemental Notes on Statistical Inference<a class="anchor" aria-label="anchor" href="#supplemental-notes-on-statistical-inference"><i class="fas fa-link"></i></a>
</h2>
<div id="hypothesis-statements" class="section level3" number="2.6.1">
<h3>
<span class="header-section-number">2.6.1</span> Hypothesis statements<a class="anchor" aria-label="anchor" href="#hypothesis-statements"><i class="fas fa-link"></i></a>
</h3>
<p>Let’s consider a <span class="math inline">\(t\)</span> test for the regression parameter, <span class="math inline">\(\beta_1\)</span>. Depending on context, the following could be null and alternative hypotheses</p>
<ul>
<li>
<span class="math inline">\(H_0: \beta_1 = 0, H_a: \beta_1 \neq 0\)</span>.</li>
<li>
<span class="math inline">\(H_0: \beta_1 = 0, H_a: \beta_1 &gt; 0\)</span>.</li>
<li>
<span class="math inline">\(H_0: \beta_1 = 0, H_a: \beta_1 &lt; 0\)</span>.</li>
</ul>
<p>The null hypothesis should be stated as a statement of <strong>equality</strong>. This concept holds true for hypothesis tests in general. Some other books / resources might state them as</p>
<ul>
<li>
<span class="math inline">\(H_0: \beta_1 = 0, H_a: \beta_1 \neq 0\)</span>.</li>
<li>
<span class="math inline">\(H_0: \beta_1 \leq 0, H_a: \beta_1 &gt; 0\)</span>.</li>
<li>
<span class="math inline">\(H_0: \beta_1 \geq 0, H_a: \beta_1 &lt; 0\)</span>.</li>
</ul>
<p>I prefer using the equality statement for the null hypothesis for the following reasons (theoretical, pedagogical, practical):</p>
<ol style="list-style-type: decimal">
<li>The null hypothesis being an equality aligns with the definition of the p-value.</li>
</ol>
<ul>
<li>The p-value is the probability of observing our sample estimate (or a value more extreme), if the null hypothesis is true (i.e. <span class="math inline">\(\beta_1\)</span> is truly 0). This is what we are assuming in the calculation for the test statistic.</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>People tend to get confused between the null and alternative hypotheses if both involve inequalities (the alternative is the hypothesis you are trying to support).</li>
<li>Conclusions are made in terms of supporting (or not supporting) the alternative hypothesis.</li>
</ol>
</div>
<div id="sample-size-and-statistical-inference" class="section level3" number="2.6.2">
<h3>
<span class="header-section-number">2.6.2</span> Sample size and statistical inference<a class="anchor" aria-label="anchor" href="#sample-size-and-statistical-inference"><i class="fas fa-link"></i></a>
</h3>
<p>Generally speaking, there is a relationship between sample size and statistical inference (assuming other characteristics remain the same and our sample was randomly obtained or representative of the population of interest):</p>
<ul>
<li>Larger sample sizes (typically) lead to narrower confidence intervals (more precise intervals).</li>
<li>Sample estimates based on larger samples are more likely to be closer to the true parameters.</li>
<li>Larger sample (typically) lead to more evidence against the null hypothesis.
<ul>
<li>This means a larger sample size leads to a more powerful test. The power of a test is the probability a hypothesis test is able to correctly reject the null hypothesis.</li>
</ul>
</li>
</ul>
<div id="small-sample-sizes" class="section level4" number="2.6.2.1">
<h4>
<span class="header-section-number">2.6.2.1</span> Small sample sizes<a class="anchor" aria-label="anchor" href="#small-sample-sizes"><i class="fas fa-link"></i></a>
</h4>
<p>Small sample sizes tend to result in:</p>
<ul>
<li>Confidence intervals that are wide.</li>
<li>Sample estimates that are more likely to be further away from the true parameters.</li>
<li>Hypothesis tests that are more likely to incorrectly fail to reject the null hypothesis when the alternative hypothesis is true.</li>
</ul>
<p>While larger sample sizes have their advantages, there are also some disadvantages with sample sizes that are extremely large.</p>
</div>
<div id="large-sample-sizes" class="section level4" number="2.6.2.2">
<h4>
<span class="header-section-number">2.6.2.2</span> Large sample sizes<a class="anchor" aria-label="anchor" href="#large-sample-sizes"><i class="fas fa-link"></i></a>
</h4>
<p>A “statistically significant” result does not necessarily mean that the result has practical consequences. Suppose a 95% confidence interval for <span class="math inline">\(\beta_1\)</span> is <span class="math inline">\((0.001, 0.002)\)</span>. The interval excludes 0, so it is “statistically significantly” different from 0 (because it is!), but does this result have practical consequences? A narrow CI that barely excludes the null value can happen when we have a large sample size.</p>
<p>If one was to conduct the corresponding hypothesis test, we would reject the null hypothesis that <span class="math inline">\(\beta_1 = 0\)</span>. With large sample sizes, hypothesis tests are sensitive to small departures from the null hypothesis.</p>
<p>In such instances, it may be worth considering hypothesis tests involving a different value in the null hypothesis, one that makes sense for your question. For example, a practically significant slope may need to be greater than a specific numerical value for a certain context.</p>
<ul>
<li>Statistical inference to assess statistical significance.</li>
<li>Subject area knowledge to assess practical significance.</li>
</ul>
</div>
<div id="questions" class="section level4" number="2.6.2.3">
<h4>
<span class="header-section-number">2.6.2.3</span> Questions<a class="anchor" aria-label="anchor" href="#questions"><i class="fas fa-link"></i></a>
</h4>
<p>Are the following results statistically significant? If so, are the results also practically significant? Assume a two-sided test with a null value of 0 (These are made up examples):</p>
<ol style="list-style-type: decimal">
<li><p>In assessing if studying more is associated with better test scores, a SLR is carried out with test scores (out of 100 points) against study time (in hours). The 95% confidence interval for the slope <span class="math inline">\(\beta_1\)</span> is (5.632, 7.829).</p></li>
<li><p>A SLR is carried out to explore the linear relationship between number of years in school with income (in thousands of dollars). The 95% confidence interval for the slope <span class="math inline">\(\beta_1\)</span> is (0.051, 0.243).</p></li>
</ol>
</div>
</div>
<div id="cautions-using-slr-and-correlation" class="section level3" number="2.6.3">
<h3>
<span class="header-section-number">2.6.3</span> Cautions using SLR and Correlation<a class="anchor" aria-label="anchor" href="#cautions-using-slr-and-correlation"><i class="fas fa-link"></i></a>
</h3>
<p>Simple linear regression and correlation are meant for assessing <strong>linear</strong> relationships. If the relationship is not linear, we will need to transform the variable(s) (so the transformed variables have a linear relationship. Will explore this in Module <a href="#diag"><strong>??</strong></a>).</p>
<ul>
<li>Always verify via a scatterplot that the relationship is at least approximately linear.</li>
<li>A high correlation or a significant estimated slope by themselves do not prove that we have a strong linear relationship between the variables. Conversely, a correlation close to 0 or an insignificant estimated slope is also not proof that we do not have a relationship between the variables.</li>
</ul>
<div id="outliers" class="section level4" number="2.6.3.1">
<h4>
<span class="header-section-number">2.6.3.1</span> Outliers<a class="anchor" aria-label="anchor" href="#outliers"><i class="fas fa-link"></i></a>
</h4>
<p>SLR and correlation are sensitive to outliers / influential observations. Generally speaking, these are data that are “far away” or very different from the rest of the observations. These data points can be visually inspected from a scatterplot. Some potential considerations when dealing with such data points:</p>
<ul>
<li>Investigate these observations. There is usually something that is making them ``stand out” from the rest of the data.</li>
<li>Data entry errors that can be corrected. Be sure to mention in the report.</li>
<li>Revisit how the data were sampled. Perhaps the data point is is not part of the population of interest. If so, data point can be removed (this is legitimate), but be sure to mention in the report.</li>
</ul>
<p>With regards to regression analysis:</p>
<ul>
<li>Exclusion of data points must be clearly documented.</li>
<li>Fit the regression with and without the data points in question, and see how similar or different the conclusions become.</li>
<li>If the data points have large value(s) on the predictor and/or response, a log transformation on the variable can pull in the large values.</li>
<li>Consider subsetting your data and create separate models for each subset; or focus on a subset and make it clear your analysis is for a subset.</li>
<li>Knowing your data and context can help a lot in these decisions.</li>
</ul>
</div>
<div id="association-and-causation" class="section level4" number="2.6.3.2">
<h4>
<span class="header-section-number">2.6.3.2</span> Association and causation<a class="anchor" aria-label="anchor" href="#association-and-causation"><i class="fas fa-link"></i></a>
</h4>
<p>Two correlated variables do not mean that one variable causes the other variable to change. For example, consider a plot of ice cream consumption and deaths by drowning during various months. There may be some positive correlation, and clearly, eating more ice cream does not cause more drownings. The correlation can be explained by a third (lurking) variable: the weather.</p>
<p>A <strong>lurking variable</strong> is a variable that has an impact on the relationship between the variables being studied, but is itself not studied.</p>
<p>A carefully designed <strong>randomized experiment</strong> can control for lurking variables, and causal relationships can be established. Typically, such experiments include:</p>
<ul>
<li>A control group and a treatment group.</li>
<li>Random assignment of large number of observations into the treatment and control groups. Due to the random assignment, the general characteristics of of subjects in each group are similar.</li>
</ul>
<p>Lurking variables are always an issue with <strong>observational studies</strong>. Researchers in observational studies do not intervene with the observations and simply observe the data that the observations generate. Causal relationships are much more difficult to establish with observational studies.</p>
</div>
<div id="questions-1" class="section level4" number="2.6.3.3">
<h4>
<span class="header-section-number">2.6.3.3</span> Questions<a class="anchor" aria-label="anchor" href="#questions-1"><i class="fas fa-link"></i></a>
</h4>
<ol style="list-style-type: decimal">
<li><p>Consider the <code>palmerpenguins</code> dataset that we have been working on. The data contain size measurements for three different species of penguins on three islands in the Palmer Archipelago, Antarctica over three years. Is this an observational study or randomized experiment?</p></li>
<li><p>A fertilizer company wishes to evaluate how effective a new fertilizer is in terms of improving the yield of crops. A large field is divided into many smaller plots, and each smaller plot is randomly assigned to receive either the new fertilizer or the standard fertilizer. Is this an observational study or randomized experiment?</p></li>
<li><p>A professor wishes to evaluate the effectiveness of various teaching methods (traditional vs flipped classroom). The professor uses the traditional approach for a section that meets on Mondays, Wednesdays, and Fridays from 9 to 10am and uses the flipped classroom approach for a section that meets on Mondays, Wednesdays, and Fridays from 2 to 3pm. Students were free to choose whichever section that wanted to register for, with no knowledge of the teaching method being used. What are some potential lurking variables in this study?</p></li>
</ol>
</div>
</div>
</div>
<div id="r-tutorial-1" class="section level2" number="2.7">
<h2>
<span class="header-section-number">2.7</span> R Tutorial<a class="anchor" aria-label="anchor" href="#r-tutorial-1"><i class="fas fa-link"></i></a>
</h2>
<p>For this tutorial, we will continue to work with the dataset <code>elmhurst</code> from the <code>openintro</code> package in R.</p>
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://openintrostat.github.io/openintro/">openintro</a></span><span class="op">)</span></span>
<span><span class="va">Data</span><span class="op">&lt;-</span><span class="fu">openintro</span><span class="fu">::</span><span class="va"><a href="https://openintrostat.github.io/openintro/reference/elmhurst.html">elmhurst</a></span></span></code></pre></div>
<p>The key pieces of information are:</p>
<ul>
<li>A random sample of 50 students (all freshman from the 2011 class at Elmhurst College).</li>
<li>Family income of the student (units are missing).</li>
<li>Gift aid, in $1000s.</li>
</ul>
<p>We want to explore how family income may be related to gift aid, in a simple linear regression framework.</p>
<div id="hypothesis-test-for-beta_1-and-beta_0" class="section level3 unnumbered">
<h3>Hypothesis test for <span class="math inline">\(\beta_1\)</span> (and <span class="math inline">\(\beta_0\)</span>)<a class="anchor" aria-label="anchor" href="#hypothesis-test-for-beta_1-and-beta_0"><i class="fas fa-link"></i></a>
</h3>
<p>Applying the <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> function to <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> gives the results of hypothesis tests for <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_0\)</span>:</p>
<div class="sourceCode" id="cb55"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##Fit a regression model</span></span>
<span><span class="va">result</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">gift_aid</span><span class="op">~</span><span class="va">family_income</span>, data<span class="op">=</span><span class="va">Data</span><span class="op">)</span></span>
<span></span>
<span><span class="co">##look at t stats and F stat</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = gift_aid ~ family_income, data = Data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -10.1128  -3.6234  -0.2161   3.1587  11.5707 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   24.31933    1.29145  18.831  &lt; 2e-16 ***
## family_income -0.04307    0.01081  -3.985 0.000229 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 4.783 on 48 degrees of freedom
## Multiple R-squared:  0.2486, Adjusted R-squared:  0.2329 
## F-statistic: 15.88 on 1 and 48 DF,  p-value: 0.0002289</code></pre>
<p>Under coefficients, we can see the results of the hypothesis tests for <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_0\)</span>. Specifically, for <span class="math inline">\(\beta_1\)</span>:</p>
<ul>
<li>
<span class="math inline">\(\hat{\beta}_1\)</span> = -0.0430717</li>
<li>
<span class="math inline">\(se(\hat{\beta}_1)\)</span> = 0.0108095</li>
<li>the test statistic is <span class="math inline">\(t\)</span> = -3.984621</li>
<li>the corresponding p-value is 2.2887345^{-4}</li>
</ul>
<p>You can work out the p-value using R (slight difference due to rounding):</p>
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##pvalue</span></span>
<span><span class="fl">2</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">pt</a></span><span class="op">(</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="op">-</span><span class="fl">3.985</span><span class="op">)</span>, df <span class="op">=</span> <span class="fl">50</span><span class="op">-</span><span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.0002285996</code></pre>
<p>Or find the critical value using R:</p>
<div class="sourceCode" id="cb59"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##critical value</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="fl">0.05</span><span class="op">/</span><span class="fl">2</span>, df <span class="op">=</span> <span class="fl">50</span><span class="op">-</span><span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 2.010635</code></pre>
<p>Either way, we end up rejecting the null hypothesis. The data support the claim that there is a linear association between gift aid and family income.</p>
<p>Note:</p>
<ul>
<li><p>the <span class="math inline">\(t\)</span> tests for regression coefficients are based on <span class="math inline">\(H_0: \beta_j = 0, H_a: \beta_j \neq 0\)</span>. The reported p-value is based on this set of null and alternative hypotheses. If your null and alternative hypotheses are different, you will need to compute your own test statistic and p-value.</p></li>
<li><p>For SLR, the two-sided <span class="math inline">\(t\)</span> test for <span class="math inline">\(\beta_1\)</span> gives the exact same result as the ANOVA <span class="math inline">\(F\)</span> test. Notice the p-values are the same. The <span class="math inline">\(F\)</span> statistic of <span class="math inline">\(15.88\)</span> is the squared of the <span class="math inline">\(t\)</span> statistic, <span class="math inline">\((-3.985)^2\)</span>.</p></li>
</ul>
</div>
<div id="confidence-interval-for-beta_1-and-beta_0" class="section level3 unnumbered">
<h3>Confidence interval for <span class="math inline">\(\beta_1\)</span> (and <span class="math inline">\(\beta_0\)</span>)<a class="anchor" aria-label="anchor" href="#confidence-interval-for-beta_1-and-beta_0"><i class="fas fa-link"></i></a>
</h3>
<p>To find the 95% confidence intervals for the coefficients, we use the <code><a href="https://rdrr.io/r/stats/confint.html">confint()</a></code> function:</p>
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##to produce 95% CIs for all regression coefficients</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html">confint</a></span><span class="op">(</span><span class="va">result</span>,level <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span></span></code></pre></div>
<pre><code>##                     2.5 %      97.5 %
## (Intercept)   21.72269421 26.91596380
## family_income -0.06480555 -0.02133775</code></pre>
<p>The 95% CI for <span class="math inline">\(\beta_1\)</span> is (-0.0648056, -0.0213378). We have 95% confidence that for each additional thousand dollars in family income, the predicted gift aid decreases between $21.3378 and $64.8056.</p>
</div>
<div id="confidence-interval-for-mean-response-for-given-x" class="section level3 unnumbered">
<h3>Confidence interval for mean response for given x<a class="anchor" aria-label="anchor" href="#confidence-interval-for-mean-response-for-given-x"><i class="fas fa-link"></i></a>
</h3>
<p>Suppose we want a confidence interval for the average gift aid for Elmhurst College students with family income of 80 thousand dollars. We can use the <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> function:</p>
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##to produce 95% CI for the mean response when x=80, </span></span>
<span><span class="va">newdata</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>family_income<span class="op">=</span><span class="fl">80</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">result</span>,<span class="va">newdata</span>,level<span class="op">=</span><span class="fl">0.95</span>, interval<span class="op">=</span><span class="st">"confidence"</span><span class="op">)</span></span></code></pre></div>
<pre><code>##       fit      lwr      upr
## 1 20.8736 19.43366 22.31353</code></pre>
<p>The 95% CI for the mean gift aid for students with family income of 80 thousand dollars is (19.4336609, 22.3135327). We have 95% confidence the mean gift aid for students with family income of 80 thousand dollars is between $19 433.66 and $22 313.53.</p>
</div>
<div id="prediction-interval-for-a-response-for-a-given-x" class="section level3 unnumbered">
<h3>Prediction interval for a response for a given x<a class="anchor" aria-label="anchor" href="#prediction-interval-for-a-response-for-a-given-x"><i class="fas fa-link"></i></a>
</h3>
<p>For a prediction interval for the gift aid of an Elmhurst College student with family income of 80 thousand dollars:</p>
<div class="sourceCode" id="cb65"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##and the 95% PI for the response of an observation when x=80</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">result</span>,<span class="va">newdata</span>,level<span class="op">=</span><span class="fl">0.95</span>, interval<span class="op">=</span><span class="st">"prediction"</span><span class="op">)</span></span></code></pre></div>
<pre><code>##       fit      lwr      upr
## 1 20.8736 11.15032 30.59687</code></pre>
<p>We have 95% confidence that for an Elmhurst College student with family income of 80, this student’s gift aid is between $11 150.32 and $30 596.87.</p>
</div>
<div id="visualization-of-ci-for-mean-response-given-x-and-pi-of-response-given-x" class="section level3 unnumbered">
<h3>Visualization of CI for mean response given x and PI of response given x<a class="anchor" aria-label="anchor" href="#visualization-of-ci-for-mean-response-given-x-and-pi-of-response-given-x"><i class="fas fa-link"></i></a>
</h3>
<p>When using the <code><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot()</a></code> function to create a scatterplot, we can overlay the SLR equation by adding a layer via <code>geom_smooth(method = lm)</code>. By default, the CI for the mean response for each value of the predictor gets overlaid as well. In the previous tutorial, we removed this by adding <code>se=FALSE</code> inside <code><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth()</a></code>:</p>
<div class="sourceCode" id="cb67"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##regular scatterplot</span></span>
<span><span class="co">##with regression line overlaid, and bounds of CI for mean y</span></span>
<span><span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">Data</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">family_income</span>, y<span class="op">=</span><span class="va">gift_aid</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method<span class="op">=</span><span class="va">lm</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x<span class="op">=</span><span class="st">"Family Income"</span>, </span>
<span>       y<span class="op">=</span><span class="st">"Gift Aid"</span>, </span>
<span>       title<span class="op">=</span><span class="st">"Scatterplot of Gift Aid against Family Income"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## `geom_smooth()` using formula = 'y ~ x'</code></pre>
<div class="inline-figure"><img src="bookdown-demo_files/figure-html/unnamed-chunk-41-1.png" width="672"></div>
<p>Overlaying prediction intervals require a bit more work. We need to compute the lower and upper bounds of the PI for each value of the predictor:</p>
<div class="sourceCode" id="cb69"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##find PIs for each observation</span></span>
<span><span class="va">preds</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">result</span>, interval<span class="op">=</span><span class="st">"prediction"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Warning in predict.lm(result, interval = "prediction"): predictions on current data refer to _future_ responses</code></pre>
<p>Previously, when we used the <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> function, we provided the numerical value of <span class="math inline">\(x\)</span> to make a prediction on. If this is not supplied, the function will use all the current values of <span class="math inline">\(x\)</span> to make predictions, and will actually print out a warning message. For our purpose, this is not an issue since this is exactly what we want.</p>
<p>We then add <code>preds</code> to the data frame in order to overlay the lower and upper bounds on the scatterplot, by adding extra layers via <code><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line()</a></code> in the <code><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot()</a></code> function:</p>
<div class="sourceCode" id="cb71"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##add preds to data frame</span></span>
<span><span class="va">Data</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">Data</span>,<span class="va">preds</span><span class="op">)</span></span>
<span></span>
<span><span class="co">##overlay PIs via geom_line()</span></span>
<span><span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">Data</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">family_income</span>, y<span class="op">=</span><span class="va">gift_aid</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y<span class="op">=</span><span class="va">lwr</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"red"</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y<span class="op">=</span><span class="va">upr</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"red"</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method<span class="op">=</span><span class="va">lm</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x<span class="op">=</span><span class="st">"Family Income"</span>, </span>
<span>       y<span class="op">=</span><span class="st">"Gift Aid"</span>, </span>
<span>       title<span class="op">=</span><span class="st">"Scatterplot of Gift Aid against Family Income"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## `geom_smooth()` using formula = 'y ~ x'</code></pre>
<div class="inline-figure"><img src="bookdown-demo_files/figure-html/unnamed-chunk-43-1.png" width="672"></div>
<p>As mentioned in the notes, the CI captures the location of the regression line, whereas the PI captures the data points.</p>

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="slr.html"><span class="header-section-number">1</span> Basics with Simple Linear Regression (SLR)</a></div>
<div class="empty"></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#inf"><span class="header-section-number">2</span> Inference with Simple Linear Regression (SLR)</a></li>
<li>
<a class="nav-link" href="#introduction"><span class="header-section-number">2.1</span> Introduction</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#review-from-previous-module"><span class="header-section-number">2.1.1</span> Review from previous module</a></li></ul>
</li>
<li>
<a class="nav-link" href="#hypothesis-testing-in-slr"><span class="header-section-number">2.2</span> Hypothesis Testing in SLR</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#distribution-of-least-squares-estimators"><span class="header-section-number">2.2.1</span> Distribution of least squares estimators</a></li>
<li><a class="nav-link" href="#testing-regression-coefficients"><span class="header-section-number">2.2.2</span> Testing regression coefficients</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#confidence-intervals-for-regression-coefficients"><span class="header-section-number">2.3</span> Confidence Intervals for Regression Coefficients</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#thought-questions"><span class="header-section-number">2.3.1</span> Thought questions</a></li></ul>
</li>
<li><a class="nav-link" href="#ci-of-the-mean-response"><span class="header-section-number">2.4</span> CI of the Mean Response</a></li>
<li>
<a class="nav-link" href="#pi-of-a-new-response"><span class="header-section-number">2.5</span> PI of a New Response</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#thought-questions-1"><span class="header-section-number">2.5.1</span> Thought questions</a></li></ul>
</li>
<li>
<a class="nav-link" href="#supplemental-notes-on-statistical-inference"><span class="header-section-number">2.6</span> Supplemental Notes on Statistical Inference</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#hypothesis-statements"><span class="header-section-number">2.6.1</span> Hypothesis statements</a></li>
<li><a class="nav-link" href="#sample-size-and-statistical-inference"><span class="header-section-number">2.6.2</span> Sample size and statistical inference</a></li>
<li><a class="nav-link" href="#cautions-using-slr-and-correlation"><span class="header-section-number">2.6.3</span> Cautions using SLR and Correlation</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#r-tutorial-1"><span class="header-section-number">2.7</span> R Tutorial</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#hypothesis-test-for-beta_1-and-beta_0">Hypothesis test for \(\beta_1\) (and \(\beta_0\))</a></li>
<li><a class="nav-link" href="#confidence-interval-for-beta_1-and-beta_0">Confidence interval for \(\beta_1\) (and \(\beta_0\))</a></li>
<li><a class="nav-link" href="#confidence-interval-for-mean-response-for-given-x">Confidence interval for mean response for given x</a></li>
<li><a class="nav-link" href="#prediction-interval-for-a-response-for-a-given-x">Prediction interval for a response for a given x</a></li>
<li><a class="nav-link" href="#visualization-of-ci-for-mean-response-given-x-and-pi-of-response-given-x">Visualization of CI for mean response given x and PI of response given x</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Linear Models for Data Science</strong>" was written by Jeffrey Woo. It was last built on 2025-06-09.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
