<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 10 Linear Regression | Understanding Uncertainty Course Notes</title>
<meta name="author" content="Jeffrey Woo">
<meta name="description" content="10.1 Introduction There is a broad range of statistical methods available for us to learn about data. Broadly speaking, these methods can be classified as supervised and unsupervised. Supervised...">
<meta name="generator" content="bookdown 0.43 with bs4_book()">
<meta property="og:title" content="Chapter 10 Linear Regression | Understanding Uncertainty Course Notes">
<meta property="og:type" content="book">
<meta property="og:description" content="10.1 Introduction There is a broad range of statistical methods available for us to learn about data. Broadly speaking, these methods can be classified as supervised and unsupervised. Supervised...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 10 Linear Regression | Understanding Uncertainty Course Notes">
<meta name="twitter:description" content="10.1 Introduction There is a broad range of statistical methods available for us to learn about data. Broadly speaking, these methods can be classified as supervised and unsupervised. Supervised...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.9.0/transition.js"></script><script src="libs/bs3compat-0.9.0/tabs.js"></script><script src="libs/bs3compat-0.9.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Understanding Uncertainty Course Notes</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="descriptive.html"><span class="header-section-number">1</span> Descriptive Statistics</a></li>
<li><a class="" href="probability.html"><span class="header-section-number">2</span> Probability</a></li>
<li><a class="" href="discrete-random-variables.html"><span class="header-section-number">3</span> Discrete Random Variables</a></li>
<li><a class="" href="continuous-random-variables.html"><span class="header-section-number">4</span> Continuous Random Variables</a></li>
<li><a class="" href="joint-distributions.html"><span class="header-section-number">5</span> Joint Distributions</a></li>
<li><a class="" href="inequalities-limit-theorems-and-simulations.html"><span class="header-section-number">6</span> Inequalities, Limit Theorems, and Simulations</a></li>
<li><a class="" href="est.html"><span class="header-section-number">7</span> Estimation</a></li>
<li><a class="" href="confidence-intervals.html"><span class="header-section-number">8</span> Confidence Intervals</a></li>
<li><a class="" href="hypothesis-testing.html"><span class="header-section-number">9</span> Hypothesis Testing</a></li>
<li><a class="active" href="linear-regression.html"><span class="header-section-number">10</span> Linear Regression</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="linear-regression" class="section level1" number="10">
<h1>
<span class="header-section-number">10</span> Linear Regression<a class="anchor" aria-label="anchor" href="#linear-regression"><i class="fas fa-link"></i></a>
</h1>
<div id="introduction-6" class="section level2" number="10.1">
<h2>
<span class="header-section-number">10.1</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction-6"><i class="fas fa-link"></i></a>
</h2>
<p>There is a broad range of statistical methods available for us to learn about data. Broadly speaking, these methods can be classified as <strong>supervised</strong> and <strong>unsupervised</strong>. Supervised methods involve relating a response variable with predictors, whereas unsupervised methods do not make a distinction between response variables and predictors and instead want to find structure or patterns in the data.</p>
<p>Supervised methods generally have two primary uses:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Association</strong>: Quantify the relationship between variables. How does a change in the predictor variable change the value of the response variable?</li>
<li>
<strong>Prediction</strong>: Predict a future value of a response variable, using information from predictor variables.</li>
</ol>
<p>We always distinguish between a <strong>response variable</strong>, denoted by <span class="math inline">\(y\)</span>, and a <strong>predictor variable</strong>, denoted by <span class="math inline">\(x\)</span>. In most supervised methods, we say that the response variable can be approximated by some mathematical function, denoted by <span class="math inline">\(f\)</span>, of the predictor variable, i.e.</p>
<p><span class="math display">\[
y \approx f(x).
\]</span></p>
<p>Oftentimes, we write this relationship as</p>
<p><span class="math display">\[
y = f(x) + \epsilon,
\]</span></p>
<p>where <span class="math inline">\(\epsilon\)</span> denotes a <strong>random error term</strong>, with a mean of 0. The error term cannot be predicted based on the data we have.</p>
<p>There are various methods to estimate <span class="math inline">\(f\)</span>. Once we estimate <span class="math inline">\(f\)</span>, we can use our method for association and / or prediction.</p>
<p>In this module, we will introduce one of the most traditional supervised methods: <strong>linear regression</strong>. It is used when there is a single response variable that is quantitative. The predictors could be quantitative or categorical.</p>
<div id="motivation" class="section level3" number="10.1.1">
<h3>
<span class="header-section-number">10.1.1</span> Motivation<a class="anchor" aria-label="anchor" href="#motivation"><i class="fas fa-link"></i></a>
</h3>
<p>Why do we learn about linear regression?</p>
<ul>
<li><p>Linear regression is widely used in many fields, and, under certain conditions, does well in the two primary purposes of supervised methods: association and prediction. Other methods may be better at one of these purposes, but usually at the expense of the other purpose. The most important thing is to know what questions you have in order to select the right method that is best for your question.</p></li>
<li><p>Linear regression is fairly easy to interpret and explain to others who may want to know how the method works. Other methods are generally more complicated and can feel like a black-box when explaining to others, leading to less confidence in the method.</p></li>
<li><p>A lot of the ideas used in other methods can be viewed as an extension or a variation of linear regression. Once you understand how linear regression works, it becomes easier to understand how other methods work.</p></li>
</ul>
</div>
<div id="toy-example" class="section level3" number="10.1.2">
<h3>
<span class="header-section-number">10.1.2</span> Toy Example<a class="anchor" aria-label="anchor" href="#toy-example"><i class="fas fa-link"></i></a>
</h3>
<p>The most common way of visualizing the relationship between one quantitative predictor variable and one quantitative response variable is with a scatter plot. In the simulated example below, we have data from 6000 UVa undergraduate students on the amount of time they spend studying in a week (in minutes), and how many courses they are taking in the semester (3 or 4 credit courses). Figure <a href="linear-regression.html#fig:10-scatter">10.1</a> displays the scatter plot.</p>
<div class="sourceCode" id="cb184"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##create dataframe</span></span>
<span><span class="va">df</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">study</span>,<span class="va">courses</span><span class="op">)</span></span>
<span></span>
<span><span class="co">##fit regression</span></span>
<span><span class="va">result</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">study</span><span class="op">~</span><span class="va">courses</span>, data<span class="op">=</span><span class="va">df</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb185"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##create scatterplot with regression line overlaid</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">courses</span>, <span class="va">df</span><span class="op">$</span><span class="va">study</span>, xlab<span class="op">=</span><span class="st">"# of Courses"</span>, ylab<span class="op">=</span><span class="st">"Study Time (Mins)"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:10-scatter"></span>
<img src="bookdown-demo_files/figure-html/10-scatter-1.png" alt="Scatterplot of Study Time against Number of Courses Taken" width="672"><p class="caption">
Figure 10.1: Scatterplot of Study Time against Number of Courses Taken
</p>
</div>
<p>Figure <a href="linear-regression.html#fig:10-scatter">10.1</a> could help us with the following questions:</p>
<ul>
<li>Are study time and the number of courses taken related to one another?</li>
<li>How strong is this relationship?</li>
<li>Could we use the data to make a prediction for the study time of a student who is not in this scatterplot?</li>
</ul>
<p>These questions can be answered using linear regression.</p>
</div>
</div>
<div id="simple-linear-regression" class="section level2" number="10.2">
<h2>
<span class="header-section-number">10.2</span> Simple Linear Regression<a class="anchor" aria-label="anchor" href="#simple-linear-regression"><i class="fas fa-link"></i></a>
</h2>
<p>In this module, we will keep things simple by only considering a single quantitative predictor. Such a regression is called <strong>simple linear regression (SLR)</strong> to emphasize that only one predictor is being considered. We will briefly touch on multiple linear regression (MLR) when multiple predictors are involved later in this module, and you will learn more about linear regression next semester.</p>
<div id="model-setup" class="section level3" number="10.2.1">
<h3>
<span class="header-section-number">10.2.1</span> Model Setup<a class="anchor" aria-label="anchor" href="#model-setup"><i class="fas fa-link"></i></a>
</h3>
<p>In SLR, the function <span class="math inline">\(f\)</span> that relates the predictor variable with the response variable is typically <span class="math inline">\(\beta_0 + \beta_1 x\)</span>. Mathematically, we express this as</p>
<p><span class="math display">\[
y \approx f(x) = \beta_0 + \beta_1 x,
\]</span></p>
<p>or in other words, that the response variable has an approximately linear relationship with the predictor variable. So the SLR model is written as</p>
<p><span class="math display" id="eq:10-SLRmod">\[\begin{equation}
y_i=\beta_0+\beta_{1}x_i + \epsilon_i,
\tag{10.1}
\end{equation}\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(y_i\)</span> denotes the value of the response variable for observation <span class="math inline">\(i\)</span>,</li>
<li>
<span class="math inline">\(x_i\)</span> denotes the value of the predictor for observation <span class="math inline">\(i\)</span>,</li>
<li>
<span class="math inline">\(\epsilon_i\)</span> denotes the value of the error for observation <span class="math inline">\(i\)</span>,</li>
<li>
<span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are parameters in the SLR model, and we want to estimate them. These parameters are sometimes called <strong>regression coefficients</strong>.</li>
<li>
<span class="math inline">\(\beta_1\)</span> is also called the <strong>slope</strong>.</li>
<li>
<span class="math inline">\(\beta_0\)</span> is also called the <strong>intercept</strong>.</li>
</ul>
<p>In linear regression, we make some assumptions about the error term <span class="math inline">\(\epsilon\)</span>:</p>
<p><span class="math display" id="eq:10-assumptions">\[\begin{equation}
\epsilon_1,\ldots,\epsilon_n \ i.i.d. \sim N(0,\sigma^2).
\tag{10.2}
\end{equation}\]</span></p>
<p>What these assumptions mean is that for each value of the predictor variable <span class="math inline">\(x\)</span>, the response variable:</p>
<ol style="list-style-type: decimal">
<li>follows a normal distribution,</li>
<li>with expected value equal to <span class="math inline">\(\beta_0+\beta_{1} x\)</span>, i.e.</li>
</ol>
<p><span class="math display" id="eq:10-SLR">\[\begin{equation}
E(Y|X=x) = \beta_0+\beta_{1} x
\tag{10.3}
\end{equation}\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>and variance equal to <span class="math inline">\(\sigma^2\)</span>.</li>
</ol>
<p>View the video below that explains how these are derived:</p>
<p>In other words, the conditional distribution of <span class="math inline">\(Y|X=x\)</span> is <span class="math inline">\(N(\beta_0+\beta_{1} x, \sigma^2)\)</span>. Applying this to our study time example, it implies that:</p>
<ul>
<li>for students who take 3 courses, their study time follows a <span class="math inline">\(N(\beta_0 + 3\beta_1, \sigma^2)\)</span> distribution,</li>
<li>for students who take 4 courses, their study time follows a <span class="math inline">\(N(\beta_0 + 4\beta_1, \sigma^2)\)</span> distribution,</li>
<li>for students who take 5 courses, their study time follows a <span class="math inline">\(N(\beta_0 + 5\beta_1, \sigma^2)\)</span> distribution.</li>
</ul>
<p>So if we were to subset our dataframe into three subsets, one with students who take 3 courses, another subset for students who take 4 courses, and another subset for students who take 5 courses, and then create a density plot of study times for each subset, each density plot should follow a normal distribution, with different means, and the same spread.</p>
<p>Let us take a look at these density plots below in Figures <a href="linear-regression.html#fig:10-conddist3">10.2</a>, <a href="linear-regression.html#fig:10-conddist4">10.3</a>, and <a href="#fig:10-conddis5"><strong>??</strong></a> below:</p>
<div class="sourceCode" id="cb186"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb187"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##subset dataframe</span></span>
<span><span class="va">x.3</span><span class="op">&lt;-</span><span class="va">df</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">courses</span><span class="op">==</span><span class="fl">3</span><span class="op">)</span>,<span class="op">]</span></span>
<span><span class="co">##density plot of study time for students taking 3 courses</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">x.3</span>,<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">study</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_density.html">geom_density</a></span><span class="op">(</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x<span class="op">=</span><span class="st">"Study Time (Mins)"</span>, title<span class="op">=</span><span class="st">"Dist of Study Times with 3 Courses"</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:10-conddist3"></span>
<img src="bookdown-demo_files/figure-html/10-conddist3-1.png" alt="Distribution of Study Time for 3, 4, 5 Classes Taken" width="672"><p class="caption">
Figure 10.2: Distribution of Study Time for 3, 4, 5 Classes Taken
</p>
</div>
<div class="sourceCode" id="cb188"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##subset dataframe</span></span>
<span><span class="va">x.4</span><span class="op">&lt;-</span><span class="va">df</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">courses</span><span class="op">==</span><span class="fl">4</span><span class="op">)</span>,<span class="op">]</span></span>
<span><span class="co">##density plot of study time for students taking 4 courses</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">x.4</span>,<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">study</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_density.html">geom_density</a></span><span class="op">(</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x<span class="op">=</span><span class="st">"Study Time (Mins)"</span>, title<span class="op">=</span><span class="st">"Dist of Study Times with 4 Courses"</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:10-conddist4"></span>
<img src="bookdown-demo_files/figure-html/10-conddist4-1.png" alt="Distribution of Study Time for 3, 4, 5 Classes Taken" width="672"><p class="caption">
Figure 10.3: Distribution of Study Time for 3, 4, 5 Classes Taken
</p>
</div>
<div class="sourceCode" id="cb189"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##subset dataframe</span></span>
<span><span class="va">x.5</span><span class="op">&lt;-</span><span class="va">df</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">courses</span><span class="op">==</span><span class="fl">5</span><span class="op">)</span>,<span class="op">]</span></span>
<span><span class="co">##density plot of study time for students taking 5 courses</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">x.5</span>,<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">study</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_density.html">geom_density</a></span><span class="op">(</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x<span class="op">=</span><span class="st">"Study Time (Mins)"</span>, title<span class="op">=</span><span class="st">"Dist of Study Times with 5 Courses"</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:10-conddist5"></span>
<img src="bookdown-demo_files/figure-html/10-conddist5-1.png" alt="Distribution of Study Time for 3, 4, 5 Classes Taken" width="672"><p class="caption">
Figure 10.4: Distribution of Study Time for 3, 4, 5 Classes Taken
</p>
</div>
<p>Notice all of these plots are normal, with different means (centers), and similar spreads.</p>
<p>The notation on the left hand side of <a href="linear-regression.html#eq:10-SLR">(10.3)</a> denotes the <strong>expected value</strong> of the response variable, for a fixed value of the predictor variable. Therefore, the regression coefficients can be interpreted in the following manner:</p>
<ul>
<li>
<span class="math inline">\(\beta_1\)</span> denotes the change in the response variable, on average, when the predictor increases by one unit.</li>
<li>
<span class="math inline">\(\beta_0\)</span> denotes the mean of the response variable when the predictor is 0.</li>
</ul>
</div>
<div id="assessing-assumptions" class="section level3" number="10.2.2">
<h3>
<span class="header-section-number">10.2.2</span> Assessing Assumptions<a class="anchor" aria-label="anchor" href="#assessing-assumptions"><i class="fas fa-link"></i></a>
</h3>
<p>The assumptions for the error terms, <span class="math inline">\(\epsilon\)</span>, expressed in equation <a href="linear-regression.html#eq:10-assumptions">(10.2)</a>, can be re-stated with words as the following 4 assumptions:</p>
<ol style="list-style-type: decimal">
<li>For each value of the predictor, the errors have mean 0.</li>
</ol>
<ul>
<li>This implies that <span class="math inline">\(f(x) = \beta_0 + \beta_1 x\)</span> approximates the relationship between the variables well.</li>
<li>A scatter plot of the variables should show a linear relationship.</li>
<li>This is the most important assumption of the 4. If it is not met, predictions will be biased, in other words, predictions will systematically over- or under- predict the value of the response variable.</li>
</ul>
<p>The plots in Figure <a href="linear-regression.html#fig:10-ass1">10.5</a> are based on simulated data. The scatter plot shown in Figure <a href="linear-regression.html#fig:10-ass1">10.5</a>(a) is an example of when this assumption is met. As we move from left to right on the plot, the data points are generally evenly scattered on both sides of the regression line that is overlaid.</p>
<p>The scatter plot shown in Figure <a href="linear-regression.html#fig:10-ass1">10.5</a>(b) is an example of when this assumption is not met. As we move from left to right on the plot in Figure <a href="linear-regression.html#fig:10-ass1">10.5</a>(b), the data points are generally not evenly scattered on both sides of the regression line that is overlaid. The shape of the plots look more like a cruve rather than a straight line.</p>
<div class="figure">
<span style="display:block;" id="fig:10-ass1"></span>
<img src="images/10-ass1.jpg" alt="Assumption 1 Assessment"><p class="caption">
Figure 10.5: Assumption 1 Assessment
</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>For each value of the predictor, the errors have variance denoted by <span class="math inline">\(\sigma^2\)</span>.</li>
</ol>
<ul>
<li>This implies that in a scatter plot, the vertical variation of data points around the regression equation has the same magnitude everywhere.</li>
<li>If this assumption is not met, hypothesis tests and confidence intervals from the linear regression will be unreliable.</li>
</ul>
<p>The plots in Figure <a href="linear-regression.html#fig:10-ass2">10.6</a> are based on simulated data. The scatter plot shown in Figure <a href="linear-regression.html#fig:10-ass2">10.6</a>(a) is an example of when this assumption is met (this figure is actually the same as Figure <a href="linear-regression.html#fig:10-ass1">10.5</a>(a), so the data that produced these plots satisfy both assumptions). As we move from left to right on the plot, the vertical variation of the data points about the regression line is approximately constant.</p>
<p>The scatter plot shown in Figure <a href="linear-regression.html#fig:10-ass2">10.6</a>(b) is an example of when this assumption is not met. As we move from left to right on the plot in Figure <a href="linear-regression.html#fig:10-ass2">10.6</a>(b), the vertical variation of the data points about the regression line becomes larger as the value of the response variable gets larger, so the variance is not constant.</p>
<div class="figure">
<span style="display:block;" id="fig:10-ass2"></span>
<img src="images/10-ass2.jpg" alt="Assumption 2"><p class="caption">
Figure 10.6: Assumption 2
</p>
</div>
<ol start="3" style="list-style-type: decimal">
<li>The errors are independent.</li>
</ol>
<ul>
<li>This implies that the observations are independent. This is usually a by-product of how the observations were sampled. So knowing the data collection method will help assess whether this assumption is met.</li>
<li>If this assumption is not met, hypothesis tests and confidence intervals from the linear regression will be unreliable.</li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>The errors are normally distributed.</li>
</ol>
<ul>
<li>This is considered the least important of the 4 assumptions, especially with large sample sizes. This is due to the Central Limit Theorem, and that in linear regression, we write the conditional expectation (or mean) of the response variable to be equal to <span class="math inline">\(f(x) = \beta_0 + \beta_1 x\)</span>, so hypothesis tests and confidence intervals from the linear regression are likely to be reliable.</li>
</ul>
<p><em>Thought question</em>: Look at the scatter plot of the toy example in Figure <a href="#eq:10-scatter">(<strong>??</strong>)</a>. Can you explain why this scatter plot shows the first two assumptions are met for linear regression?</p>
</div>
</div>
<div id="estimating-regression-coefficients" class="section level2" number="10.3">
<h2>
<span class="header-section-number">10.3</span> Estimating Regression Coefficients<a class="anchor" aria-label="anchor" href="#estimating-regression-coefficients"><i class="fas fa-link"></i></a>
</h2>
<p>There are two methods in estimating the regression coefficients: the method of least squares and the method of maximum likelihood. For large sample sizes, these methods give similar results.</p>
<p>We will go over the method of least squares first, since this is the method that is usually used to explain to new learners and is conceptually easier to understand.</p>
<div id="method-of-least-squares" class="section level3" number="10.3.1">
<h3>
<span class="header-section-number">10.3.1</span> Method of Least Squares<a class="anchor" aria-label="anchor" href="#method-of-least-squares"><i class="fas fa-link"></i></a>
</h3>
<p>From <a href="linear-regression.html#eq:10-SLR">(10.3)</a> and <a href="linear-regression.html#eq:10-SLRmod">(10.1)</a>, we noted that we have to estimate the regression coefficients <span class="math inline">\(\beta_0, \beta_1\)</span>. We are unable to obtain numerical values of these parameters as we do not have data from the entire population. So what we do is use the data from our sample to estimate these parameters. We estimate <span class="math inline">\(\beta_0,\beta_1\)</span> using <span class="math inline">\(\hat{\beta}_0,\hat{\beta}_1\)</span> based on a sample of observations <span class="math inline">\((x_i,y_i)\)</span> of size <span class="math inline">\(n\)</span>.</p>
<p>Following <a href="linear-regression.html#eq:10-SLR">(10.3)</a> and <a href="linear-regression.html#eq:10-SLRmod">(10.1)</a>, the sample versions are</p>
<p><span class="math display" id="eq:10-fitted">\[\begin{equation}
\hat{y}=\hat{\beta}_0+\hat{\beta}_1 x
\tag{10.4}
\end{equation}\]</span></p>
<p>and</p>
<p><span class="math display" id="eq:10-fitted-model">\[\begin{equation}
y=\hat{\beta}_0+\hat{\beta}_1 x + e
\tag{10.5}
\end{equation}\]</span></p>
<p>respectively. <a href="linear-regression.html#eq:10-fitted">(10.4)</a> is called the <strong>fitted line</strong>. The line that was overlaid in the scatter plot for the toy example in Figure <a href="linear-regression.html#fig:10-scatter">10.1</a> represents the fitted line. <a href="linear-regression.html#eq:10-fitted-model">(10.5)</a> is called the <strong>estimated SLR model</strong>.</p>
<p><span class="math inline">\(\hat{\beta}_1,\hat{\beta}_0\)</span> are the estimators for <span class="math inline">\(\beta_1,\beta_0\)</span> respectively. These estimators can be interpreted in the following manner:</p>
<ul>
<li>
<span class="math inline">\(\hat{\beta}_1\)</span> denotes the change in the predicted <span class="math inline">\(y\)</span> when <span class="math inline">\(x\)</span> increases by 1 unit. Alternatively, it estimates the change in <span class="math inline">\(y\)</span>, on average, when <span class="math inline">\(x\)</span> increases by 1 unit.</li>
<li>
<span class="math inline">\(\hat{\beta}_0\)</span> denotes the predicted <span class="math inline">\(y\)</span> when <span class="math inline">\(x=0\)</span>. Alternatively, it estimates the average of <span class="math inline">\(y\)</span> when <span class="math inline">\(x=0\)</span>.</li>
</ul>
<p>From <a href="linear-regression.html#eq:10-fitted-model">(10.5)</a>, notice we use <span class="math inline">\(e\)</span> to denote the <strong>residual</strong>, or in other words, the “error” in the sample.</p>
<p>From <a href="linear-regression.html#eq:10-fitted">(10.4)</a> and <a href="linear-regression.html#eq:10-fitted-model">(10.5)</a>, we have the following quantities that we can compute:</p>
<ul>
<li>Fitted values:</li>
</ul>
<p><span class="math display" id="eq:10-fits">\[\begin{equation}
\hat{y}_i = \hat{\beta}_0+\hat{\beta}_1 x_i.
\tag{10.6}
\end{equation}\]</span></p>
<p>The <strong>fitted values</strong> are the predicted values of the response variable when the predictor is equal to some specific value. Visually, the fitted line represents each fitted value as we vary the value of the predictor.</p>
<ul>
<li>Residuals:</li>
</ul>
<p><span class="math display" id="eq:10-res">\[\begin{equation}
e_i = y_i-\hat{y}_i.
\tag{10.7}
\end{equation}\]</span></p>
<p>The <strong>residuals</strong> are the differences between the actual values of the response variable and their corresponding predicted values based on the fitted line. Visually, a residual is the vertical distance of a data point in the scatter plot from the fitted line, as shwon in Figure <a href="linear-regression.html#fig:10-res">10.7</a> below:</p>
<div class="figure">
<span style="display:block;" id="fig:10-res"></span>
<img src="images/10-residuals.png" alt="Example of Residuals. Picture from https://www.statology.org/residuals/"><p class="caption">
Figure 10.7: Example of Residuals. Picture from <a href="https://www.statology.org/residuals/" class="uri">https://www.statology.org/residuals/</a>
</p>
</div>
<ul>
<li>Sum of Squared Errors:</li>
</ul>
<p><span class="math display" id="eq:10-SSres">\[\begin{equation}
SS_{res} =  \sum\limits_{i=1}^n(y_i-\hat{y}_i)^2.
\tag{10.8}
\end{equation}\]</span></p>
<p>We compute the estimated coefficients <span class="math inline">\(\hat{\beta}_1,\hat{\beta}_0\)</span> using the <strong>method of least squares</strong>, i.e. choose the numerical values of <span class="math inline">\(\hat{\beta}_1,\hat{\beta}_0\)</span> that minimize <span class="math inline">\(SS_{res}\)</span> as given in <a href="linear-regression.html#eq:10-SSres">(10.8)</a>. We find the line which minimizes the sum of all the squared residuals on the scatter plot, hence the name method of least squares.</p>
<p>By minimizing <span class="math inline">\(SS_{res}\)</span> with respect to <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span>, the estimated coefficients in the simple linear regression equation are</p>
<p><span class="math display" id="eq:10-b1">\[\begin{equation}
\hat{\beta}_1 = \frac{\sum\limits_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum\limits_{i=1}^n(x_i-\bar{x})^2}
\tag{10.9}
\end{equation}\]</span></p>
<p>and</p>
<p><span class="math display" id="eq:10-b0">\[\begin{equation}
\hat{\beta}_0 = \bar{y}- \hat{\beta}_1 \bar{x}
\tag{10.10}
\end{equation}\]</span></p>
<p><span class="math inline">\(\hat{\beta}_1, \hat{\beta}_0\)</span> are called <strong>least squares estimators</strong>, to emphasize that these values are found by minimizing <span class="math inline">\(SS_{res}\)</span>.</p>
<p>The minimization of <span class="math inline">\(SS_{res}\)</span> with respect to <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> is done by taking the partial derivatives of <a href="#eq:SSres">(<strong>??</strong>)</a> with respect to <span class="math inline">\(\hat{\beta}_1\)</span> and <span class="math inline">\(\hat{\beta}_0\)</span>, setting these two partial derivatives equal to 0, and solving these two equations for <span class="math inline">\(\hat{\beta}_1\)</span> and <span class="math inline">\(\hat{\beta}_0\)</span>.</p>
<p>Let’s take a look at the estimated coefficients for our study time example:</p>
<div class="sourceCode" id="cb190"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##fit regression</span></span>
<span><span class="va">result</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">study</span><span class="op">~</span><span class="va">courses</span>, data<span class="op">=</span><span class="va">df</span><span class="op">)</span> <span class="co">##supply y, then x, and specify dataframe via data</span></span>
<span><span class="co">##print out the estimated coefficients</span></span>
<span><span class="va">result</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = study ~ courses, data = df)
## 
## Coefficients:
## (Intercept)      courses  
##       58.45       120.39</code></pre>
<p>From our sample of 6000 students, we have</p>
<ul>
<li>
<span class="math inline">\(\hat{\beta}_1\)</span> = 120.3930985. The predicted study time increases by 120.3930985 minutes for each additional course taken.</li>
<li>
<span class="math inline">\(\hat{\beta}_0\)</span> = 58.4482853. The predicted study time is 58.4482853 when no courses are taken. Notice this value does not make sense, as a student cannot be taking 0 courses. If you look at our data, the number of courses taken is 3, 4, or 5. So we should only use our regression when <span class="math inline">\(3 \leq x \leq 5\)</span>. We cannot use it for values of <span class="math inline">\(x\)</span> outside the range of our data. Making predictions of the response variable for predictors outside the range of the data is called <strong>extrapolation</strong> and should not be done.</li>
</ul>
<p><em>Thought question</em>: The response variable for the toy example is study time, in minutes. Suppose we convert these values to hours by dividing by 60. How will the numerical value of the estimated coefficients change? How will the interpretation of the estimated coefficients change?</p>
</div>
<div id="method-of-maximum-likelihood" class="section level3" number="10.3.2">
<h3>
<span class="header-section-number">10.3.2</span> Method of Maximum Likelihood<a class="anchor" aria-label="anchor" href="#method-of-maximum-likelihood"><i class="fas fa-link"></i></a>
</h3>
<p>We will give a brief overview of maximum likelihood estimation is carried out for simple linear regression. We had earlier written that the conditional distribution of <span class="math inline">\(Y|X=x\)</span> is <span class="math inline">\(N(\beta_0+\beta_{1} x, \sigma^2)\)</span>. We know the PDF of any normal distribution takes the form in equation <a href="continuous-random-variables.html#eq:4-pdfNormal">(4.11)</a>, which implies that we can write the PDF of this distribution as</p>
<p><span class="math display" id="eq:10-SLRpdf">\[\begin{equation}
f_{Y|X}(y|x) = \frac{1}{\sigma \sqrt{2 \pi}} \exp \left(-\frac{(y - (\beta_0+\beta_{1} x))^2}{2 \sigma^2} \right).
\tag{10.11}
\end{equation}\]</span></p>
<p>We can then write the corresponding log-likelihood function, using equation <a href="est.html#eq:7-loglike">(7.2)</a>, as</p>
<p><span class="math display" id="eq:10-SLRloglike">\[\begin{equation}
\ell(\beta_0, \beta_1, \sigma^2 | \boldsymbol{y}, \boldsymbol{x}) = -\frac{n}{2} \log(2\pi) - n \log(\sigma) - \frac{1}{2 \sigma^2} \sum_{i=1}^n \left(y_i - (\beta_0 + \beta_1 x_i) \right)^2.
\tag{10.12}
\end{equation}\]</span></p>
<p>We then take the partial derivatives of <a href="linear-regression.html#eq:10-SLRloglike">(10.12)</a> with respect to <span class="math inline">\(\hat{\beta}_1\)</span> and <span class="math inline">\(\hat{\beta}_0\)</span>, setting these two partial derivatives equal to 0, and solving these two equations for <span class="math inline">\(\hat{\beta}_1\)</span> and <span class="math inline">\(\hat{\beta}_0\)</span>. We end up with the same solutions as the method of least squares.</p>
<div class="sourceCode" id="cb192"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##fit regression</span></span>
<span><span class="va">result.mle</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">study</span><span class="op">~</span><span class="va">courses</span>, data<span class="op">=</span><span class="va">df</span><span class="op">)</span> <span class="co">##we use glm() function for ML instead</span></span>
<span><span class="co">##print out the estimated coefficients. Notice they are the same. </span></span>
<span><span class="va">result.mle</span></span></code></pre></div>
<pre><code>## 
## Call:  glm(formula = study ~ courses, data = df)
## 
## Coefficients:
## (Intercept)      courses  
##       58.45       120.39  
## 
## Degrees of Freedom: 5999 Total (i.e. Null);  5998 Residual
## Null Deviance:       63300000 
## Residual Deviance: 5317000   AIC: 57750</code></pre>
</div>
</div>
<div id="inference-with-simple-linear-regression" class="section level2" number="10.4">
<h2>
<span class="header-section-number">10.4</span> Inference with Simple Linear Regression<a class="anchor" aria-label="anchor" href="#inference-with-simple-linear-regression"><i class="fas fa-link"></i></a>
</h2>
<p>The process of using data from a sample to draw a conclusion about the population is called (statistical) <strong>inference</strong>. Two methods associated with inference are confidence intervals and hypothesis testing.</p>
<p>The most common inference deals with the slope, <span class="math inline">\(\beta_1\)</span>. We are usually assessing whether the slope is 0 or not, as a slope of 0 implies that there is no linear relationship between the variables (if the slope is 0, the value of the response is not affected by the value of the predictor).</p>
<p>We will cover the confidence interval and hypothesis test for the slope.</p>
<div id="confidence-interval" class="section level3" number="10.4.1">
<h3>
<span class="header-section-number">10.4.1</span> Confidence Interval<a class="anchor" aria-label="anchor" href="#confidence-interval"><i class="fas fa-link"></i></a>
</h3>
</div>
<div id="hypothesis-testing-1" class="section level3" number="10.4.2">
<h3>
<span class="header-section-number">10.4.2</span> Hypothesis Testing<a class="anchor" aria-label="anchor" href="#hypothesis-testing-1"><i class="fas fa-link"></i></a>
</h3>

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="hypothesis-testing.html"><span class="header-section-number">9</span> Hypothesis Testing</a></div>
<div class="empty"></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#linear-regression"><span class="header-section-number">10</span> Linear Regression</a></li>
<li>
<a class="nav-link" href="#introduction-6"><span class="header-section-number">10.1</span> Introduction</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#motivation"><span class="header-section-number">10.1.1</span> Motivation</a></li>
<li><a class="nav-link" href="#toy-example"><span class="header-section-number">10.1.2</span> Toy Example</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#simple-linear-regression"><span class="header-section-number">10.2</span> Simple Linear Regression</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#model-setup"><span class="header-section-number">10.2.1</span> Model Setup</a></li>
<li><a class="nav-link" href="#assessing-assumptions"><span class="header-section-number">10.2.2</span> Assessing Assumptions</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#estimating-regression-coefficients"><span class="header-section-number">10.3</span> Estimating Regression Coefficients</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#method-of-least-squares"><span class="header-section-number">10.3.1</span> Method of Least Squares</a></li>
<li><a class="nav-link" href="#method-of-maximum-likelihood"><span class="header-section-number">10.3.2</span> Method of Maximum Likelihood</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#inference-with-simple-linear-regression"><span class="header-section-number">10.4</span> Inference with Simple Linear Regression</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#confidence-interval"><span class="header-section-number">10.4.1</span> Confidence Interval</a></li>
<li><a class="nav-link" href="#hypothesis-testing-1"><span class="header-section-number">10.4.2</span> Hypothesis Testing</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Understanding Uncertainty Course Notes</strong>" was written by Jeffrey Woo. It was last built on 2025-07-30.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
